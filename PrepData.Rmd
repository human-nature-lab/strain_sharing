---
title: "Untitled"
output: html_document
date: "2022-12-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(readr.show_col_types = FALSE) 
```

Install necessary packages
```{r message=FALSE, warning=FALSE, include=FALSE}
if (!require("readr")) install.packages("readr")
library(readr)
if (!require("stringr")) install.packages("stringr")
library(stringr)
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("igraph")) install.packages("igraph")
library(igraph)
if (!require("vegan")) install.packages("vegan")
library(vegan)
if (!require("compositions")) install.packages("compositions")
library(compositions)
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)
if (!require("lmerTest")) install.packages("lmerTest")
library(lmerTest)
if (!require("pROC")) install.packages("pROC")
library(pROC)
if (!require("ggpubr")) install.packages("ggpubr")
library(ggpubr)
if (!require("svglite")) install.packages("svglite")
library(svglite)
if (!require("ggplotify")) install.packages("ggplotify")
library(ggplotify)
if (!require("mclust")) install.packages("mclust")
library(mclust)
library(tidyr)
library(forcats)
```

Load batch data
```{r message=TRUE, warning=FALSE, include=FALSE}
extraction_batch <- bind_rows(read_csv('~/F_BEGHINI_HM/Rn338 gDNA 032822.csv') |> select(SampleID = `Sample ID`, WIKI = `WIKI ID`, Plate, DNA_conc = `gDNA, ng/uL(Nanodrop)`), 
          read_csv('~/F_BEGHINI_HM/Honduras_gDNA_11052020.csv') |> select(SampleID, WIKI, Plate = `gDNA Plate`, DNA_conc = `NanoDrop,ng/uL`),
          read_csv('~/F_BEGHINI_HM/Ejl54 stool WGS 010523.csv') |> select(SampleID, WIKI, Plate = `gDNA Plate`, DNA_conc = `NanoDrop, ng/uL`)) |> 
  mutate( Plate = factor(str_extract(Plate, '[0-9]{6}')),
          WIKI = factor(str_split_i(WIKI, '-', 1)))

sequencing_depth <- bind_rows(
read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ13084_Read_Counts.csv") |> 
  select(SampleID=`Sample ID`, Reads), 

read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ17122_Read_Counts.csv") |> 
  select(SampleID = Sample, Reads = `Read Pairs`), 

read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ19764_Read_Counts.csv") |> 
  select(SampleID=`Sample ID`, Reads)) |> 
  group_by(SampleID) |> 
  summarize(Reads=sum(Reads))

shipping_batch <- 
  read_csv('/WORKAREA/work/HONDURAS_MICROBIOME/F_BEGHINI/COHORT1/v3/hmb_shipments_cohort1_baseline_v3.csv') |> 
  filter(str_detect(barcode, '-05$')) |> 
  select(SampleID=`barcode`, shipment_batch) |> 
  bind_rows(read_csv('/WORKAREA/home/fb343/F_BEGHINI_HM/shipment_batch_cohort2.csv'))

```

```{r}
extraction_batch |> 
  inner_join(sequencing_depth, by = join_by(SampleID)) |> #write_tsv('extraction_sequencing_batch.tsv')
  filter(str_detect(SampleID, '-15', negate=TRUE)) |> 
  arrange(SampleID) |> 
  filter(DNA_conc >= 0) |> 
  mutate(a=1) |> 
  group_by(a) |> 
  summarize(broom::tidy(cor.test(Reads, DNA_conc)))
```

Download Microbiome census Data
```{r}

#Microbiome Census Data
hmb_c1 <- read_csv("~/F_BEGHINI_HM/COHORT1/v3/hmb_respondents_cohort1_baseline_v3_f_beghini_2022-11-08.csv", na = c('NA','Dont_Know','Refused'))
hmb_c2 <- read_csv("~/F_BEGHINI_HM/COHORT2/v2/hmb_respondents_cohort2_v2_f_beghini_2022-11-08.csv", na = c('NA','Dont_Know','Refused'))

hmb_c2$mb_m05[is.na(hmb_c2$mb_m05)] <- hmb_c2$mb_m00[is.na(hmb_c2$mb_m05)]
hmb_c2$mb_m05 <- paste0(substr(hmb_c2$mb_m05,0,10), "5")

#One individual was coded incorrectly
hmb_c2$village_code[!is.na(hmb_c2$village_code) & hmb_c2$village_code == 18] <- 17

#Missing certain ones, need to clean that up

master_key <- bind_rows(hmb_c1 |> select(mb_m05, respondent_master_id),
                  hmb_c2 |> select(mb_m05, respondent_master_id)
)

hmb_census <- bind_rows(hmb_c1,hmb_c2) |> 
  mutate(BMI = (mb_d0100 / mb_d0200 **2) * 10000,
         mb_m0100 = if_else(is.na(mb_m0100), if_else(!is.na(completed_at_E6), lubridate::as_date(completed_at_E6), lubridate::as_date(completed_at_E5)), mb_m0100)) |> 
 rename(sampling_date = mb_m0100)

# Map village id to Spaniard villages
village_map <- tribble(~village_code, ~village_name_deid,
  18 , "Ermua",
  21 , "Azpeitia",
  26 , "Mungia",
  73 , "Tolosa",
  116 , "Basauri",
  144 , "Hondarribia",
  145 , "Hernani",
  162 , "Erandio",
  169 , "Sestao",
  118 , "Bermeo",
  14 , "Madera",
  41 , "Pasaia",
  140 , "Zarautz",
  89 , "Lekeitio",
  58 , "Laguardia",
  110 , "Zumaia",
  174 , "Getaria",
  5 , "Irun"
)

hmb_census <- full_join(hmb_census, village_map)

#RCT Data
demographics <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_respondents_WAVE3_v3_F_BEGHINI_2023-10-23.csv") |> 
  dplyr::select("respondent_master_id", "building_id_w3","village_name_w3",
         "b0100", "b0200","b0600","b0800","b0900")

```
Compute Diet Diversity Score
```{r}
hmb_census <- hmb_census |> 
  mutate(across(starts_with('mb_ca'), ~ case_when(as.integer(factor(.x)) / 3 == 1 ~ 1, .default = 0  ))) |>
  mutate(dds_Cereals = as.integer(mb_ca0200|mb_ca0300|mb_ca0400),
         dds_Vegetables = mb_ca1000,
         dds_Fruits = as.integer(mb_ca1100|mb_ca1200),
         dds_Meat_poultry_offal = as.integer(mb_ca1300 |mb_ca1400),
         dds_Eggs = mb_ca0900,
         dds_Fish_seafood = mb_ca1600,
         dds_Legumes = mb_ca0100,
         dds_Dairy = as.integer(mb_ca0500 | mb_ca0600 | mb_ca0700 | mb_ca0800),
         dds_Fats = as.integer(mb_ca1500 | mb_ca1900),
         dds_Sugar = as.integer(mb_ca1700 | mb_ca1800),
         DDS = rowSums(across(starts_with('dds_')))
  )

```


Strain Share
```{r}
test_ssr_num <- as.matrix(readRDS("data/sharing_rate_with_zero.RDS"))

test_ssr_num <- test_ssr_num[order(rownames(test_ssr_num)),
                             order(colnames(test_ssr_num))]


rownames(test_ssr_num) <- master_key$respondent_master_id[match(rownames(test_ssr_num),
                                                            master_key$mb_m05)]
colnames(test_ssr_num) <- master_key$respondent_master_id[match(colnames(test_ssr_num),
                                                                   master_key$mb_m05)]

strain_rate <- test_ssr_num*100
diag(strain_rate) <- 0
```


Download and prep species data
```{r}
species_data <- readr::read_tsv("data/mpa4_merged_profiles.tsv", skip = 1) |> 
  filter(stringr::str_detect(clade_name, 't__')) |> 
  select(clade_name, ends_with('-05')) |> 
  tibble::column_to_rownames('clade_name')
species_data <- species_data / 100

colnames(species_data) <- master_key$respondent_master_id[match(colnames(species_data), master_key$mb_m05)]

#Calculate CLR of species relative abundance data
species_data_clr <- species_data
species_data_clr[species_data_clr == 0 ] <- 5e-6
species_data_clr <- clr(species_data_clr)

species_bray <- vegdist(t(species_data), method = "bray")
species_bray <- as.matrix(species_bray)

#Calculate jaccard index manually
species_jaccard_sim <- vegdist(t(species_data), method = 'jaccard')
species_jaccard_sim <- as.data.frame(species_jaccard_sim)
```

Calculate coverage rates and update social network to match hmb census
```{r}
#Full edge dataframe
all_edges <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_connections_WAVE3_v3_F_BEGHINI_2021-09-27.csv", as.is = TRUE) |> 
              filter(relationship %in% c('child_over12_other_house','closest_friend','father','free_time','mother','partner','personal_private','sibling')) #Remove not get along
#Filter to villages for people we have microbiome information from
all_vils <- hmb_census %>%
  filter(respondent_master_id %in% rownames(strain_rate)) %>%
  dplyr::select(village_code) %>% distinct() %>% pull(village_code)

village_names <- c()
vill_cov = data.frame()
for(i in 1:length(all_vils)){
  vil <- all_edges %>% filter(all_edges$village_code_w3 == all_vils[i])
  vil_ids <- unique(c(vil$ego, vil$alter))
  coverage_rate <- mean(vil_ids %in% rownames(strain_rate))
  num_ppl <- sum(vil_ids %in% rownames(strain_rate))
  vill_cov <- bind_rows(vill_cov,c(village_code = all_vils[i], cov= round(coverage_rate, 3), num_ppl_mb = num_ppl, num_ppl_sn = length(vil_ids)))
  #print(paste(all_vils[i],":", round(coverage_rate, 3), num_ppl, length(vil_ids)))
  if(!is.na(coverage_rate) & coverage_rate >=.3 & num_ppl>=10){
    village_names <- c(village_names, all_vils[i])
  }
}

demographics <- demographics |> filter(village_code_w3 %in% village_names)
```

```{r}
#Filter edgelist to the villages that with sufficient microbiome coverage
#People must be in the same village as when we collected their microbiome data This always holds
all_edges <- all_edges %>%
  filter(village_code_w3 %in% village_names)

all_network_ids <- c(all_edges$ego, all_edges$alter)

#Filter edgelist to study participants who we have microbiome data for
SN <- all_edges %>% filter(ego %in% rownames(strain_rate) , alter %in% rownames(strain_rate))


hmb_census <- hmb_census |> 
  filter(respondent_master_id %in% colnames(species_data))

hmb_census <- hmb_census %>%
  filter(village_code %in% village_names)

#Check if people moved villages or houses for whom we have study data for
hmb_census_ego <- hmb_census
names(hmb_census_ego) <- paste0(names(hmb_census_ego),"_ego")
names(hmb_census_ego)[1] <- "ego"
hmb_census_alter <- hmb_census
names(hmb_census_alter) <- paste0(names(hmb_census_alter),"_alter")
names(hmb_census_alter)[1] <- "alter"


SN_census <- merge(SN, hmb_census_ego) %>% merge(hmb_census_alter)
```

```{r}
#Household data
print("Average Household Size from Microbiome Villages")
demographics %>% group_by(household_id_w3) %>%
  summarise(n = n()) %>% pull(n) %>% mean()
```


```{r}
#Get summary statistics for individuals we have microbiome and network data for
hmb_census <- hmb_census %>% filter(respondent_master_id %in% rownames(strain_rate),
                                    respondent_master_id %in% all_network_ids)
```

```{r}
#Get average age
print(paste("Mean Age:",round(mean(na.omit(hmb_census$age_at_survey)),2)))
```
```{r}
#Get sd of age
print(paste("SD Age:",round(sd(na.omit(hmb_census$age_at_survey)),2)))
```
```{r}
#Get min and max of age
print("Min/Max Age")
min(na.omit(hmb_census$age_at_survey))
max(na.omit(hmb_census$age_at_survey))
```
```{r}
#Get gender and marriage summary
#We should get the all around census data and compare to these
print("Percent Female/Male")
sum(hmb_census$gender == "woman") / nrow(hmb_census)
sum(hmb_census$gender == "man") / nrow(hmb_census)
table(hmb_census$marital_name)/nrow(hmb_census)
```
```{r}
print(paste("Total Sample Size:",nrow(hmb_census)))
```

```{r}
#Use HMB census data and only keep rct data for values we don't have
covariates <- inner_join(hmb_census, demographics, by = join_by(respondent_master_id)) %>%
  dplyr::select(-c("building_id_w3", "village_name_w3"))


#Merge on household wealth index data
household_wealth_data <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_households_WAVE3_v3_F_BEGHINI_2023_10-23.csv")
household_wealth_data <- household_wealth_data %>% dplyr::select(building_id, l0400, household_wealth_index_w3)

#Merge covariates with household wealth data
covariates <- inner_join(covariates, household_wealth_data)

#Calculate distance between villages
names(covariates)

village_centroids <- covariates %>%
  group_by(village_name) %>%
  summarize(
    village_mean_lat = mean(building_latitude),
    village_mean_long = mean(building_longitude)
  )

#Geosphere package too calculate distance in meters
library(geosphere)
village_distances <- distm(village_centroids %>% select(village_mean_lat, village_mean_long),
      fun = distHaversine) /1000
diag(village_distances) <- NA

#Get average distance to closest village
mean(apply(village_distances, MARGIN = 1, FUN = min, na.rm = TRUE))
mean(apply(village_distances, MARGIN = 1, FUN = max, na.rm = TRUE))


```


Finish Processing social network data
```{r}
SN_census <- SN_census %>% select(-c("village_name_ego", "village_name_alter", "same_building"))
names(SN_census)[names(SN_census) == "same_building_updated"] <- "same_building"
SN <- SN_census


strain_rate <- strain_rate[rownames(strain_rate) %in% rownames(species_bray),
                           colnames(strain_rate) %in% rownames(species_bray)]




#Create unique pair identifier
for(i in 1:nrow(SN)){
  combo <- paste0(SN$ego[i], SN$alter[i])
  SN$pair_key[i] <- paste((sort(str_split(combo,"")[[1]])),sep="", collapse="")
}





#add on microbiome sharing data
for(i in 1:nrow(SN)){
  if(!is.na(strain_rate[rownames(strain_rate) == SN$ego[i],colnames(strain_rate) == SN$alter[i]])){
    SN$strain_sharing_rate[i] <- strain_rate[rownames(strain_rate) == SN$ego[i],
                                           colnames(strain_rate) == SN$alter[i]]
  }
  else{
    SN$strain_sharing_rate[i] <- strain_rate[rownames(strain_rate) == SN$alter[i],
                                           colnames(strain_rate) == SN$ego[i]]
  }
  
}



#Filter social network data data to who we also have microbiome data for
SN <- SN[SN$ego %in% rownames(strain_rate) & SN$alter %in% rownames(strain_rate),]

for(i in 1:nrow(SN)){
  SN$bray_curtis_sim[i] <- species_bray[rownames(species_bray) == SN$ego[i],
                                           colnames(species_bray) == SN$alter[i]]
}

for(i in 1:nrow(SN)){
  SN$jaccard_sim[i] <- species_jaccard_sim[rownames(species_jaccard_sim) == SN$ego[i],
                                           colnames(species_jaccard_sim) == SN$alter[i]]
}

#Filter Microbiome data to who we also have social network data for
strain_rate <- strain_rate[rownames(strain_rate) %in% unique(c(SN$ego, SN$alter)),
                           colnames(strain_rate) %in% unique(c(SN$ego, SN$alter))]

#Filter covariates to individuals we also have social network data for
covariates <- covariates[covariates$respondent_master_id %in% unique(c(SN$ego, SN$alter)),]

#Changes names of relationship variable
rename_relationship_table <- c(child_over12_other_house = "Child",
                               closest_friend = "Closest Friend",
                               father = "Father",
                               free_time = "Spend Free Time",
                               mother = "Mother",
                               partner = "Partner",
                               personal_private = "Personal or Private Relationship",
                               sibling = "Sibling")

SN$relationship <- as.character(rename_relationship_table[SN$relationship])

#Get counts of unique relationships

SN %>% distinct(pair_key, relationship) %>%
  group_by(relationship) %>% summarize(n = n()) %>% arrange(n)

#Total count of nominations
SN %>% distinct(pair_key) %>% nrow()


#Average number of nominations
SN %>%
  group_by(pair_key) %>%
  mutate(n = n()) %>%
  ungroup() %>%
  distinct(pair_key, .keep_all = TRUE) %>%
  pull(n) %>%
  mean()


#Download BMI and DNA Conc data from Shiv
shiv_covar_df <- read.csv("../Data/shiv_phenotype.csv")
shiv_covar_df <- shiv_covar_df %>% select(respondent_master_id, dna_conc, BMI)

#Get list of pairs that are kin or living in the same house
family_house_pairs <- unique(SN$pair_key[SN$same_building == 1 |
                                           SN$relationship %in% c("father", "mother", "sibling", "child_over12_other_house")])


```


Create helpful datasets at the village level
```{r}
#Create auxiliary networks
#Note on data trustworthiness, do we want to impute, pareent child relationships/sibling relationships
#How to make sure we're not dropping cases that don't share anything with their first degree
#Or that none of their first degree have microbiome
#We can't tell anything about degree
#Drop from clustering too, not accurate cluster, we don't know where they fall
#Ok, so why is the other cluster fucking up
for(i in 1:nrow(all_edges)){
  combo <- paste0(all_edges$ego[i], all_edges$alter[i])
  all_edges$pair_key[i] <- paste((sort(str_split(combo,"")[[1]])),sep="", collapse="")
}

for(i in 1:length(village_names)){
  #Create social networks edge lists
  assign(paste0("sn_vil_", i), SN %>% filter(village_code_w3 == village_ids[i]))
  
  assign(paste0("sn_vil_all_", i), all_edges %>% filter(village_code_w3 == village_ids[i]))
  
  #Create social network graphs
  assign(paste0("sn_vil_graph_", i),
         igraph::simplify(graph_from_data_frame(get(paste0("sn_vil_", i)),
                                                                            directed = FALSE)))
  
  assign(paste0("sn_vil_graph_all_", i),
         igraph::simplify(graph_from_data_frame(get(paste0("sn_vil_all_", i)),
                                                                            directed = FALSE)))
  
  #Create social network graphs for scrambling
  assign(paste0("sn_vil_graph_scram_", i), get(paste0("sn_vil_graph_", i)))
  
  #Create village id Vectors
  assign(paste0("village_ids_", i),
         unique(c(get(paste0("sn_vil_", i))$ego , get(paste0("sn_vil_", i))$alter)))
  
  #Create strain sharing rate adjacency
  assign(paste0("strain_rate_vil_", i),
         strain_rate[rownames(strain_rate) %in% get(paste0("village_ids_", i)),
                     colnames(strain_rate) %in% get(paste0("village_ids_", i))])
  
  #Create strain sharing rate graph
  assign(
    paste0("strain_rate_vil_graph_", i),
    igraph::simplify(graph_from_adjacency_matrix(
      get(paste0("strain_rate_vil_", i)),
      weighted = TRUE,
      mode = c("undirected")
    ))
  )
  
  #Create strain sharing rate graph for scrambling
  assign(paste0("strain_rate_vil_graph_scram_", i),
         get(paste0("strain_rate_vil_graph_", i)))
  
  
  #Create bray adjacency
  assign(paste0("bray_vil_", i),
         species_bray[rownames(species_bray) %in% get(paste0("village_ids_", i)),
                     colnames(species_bray) %in% get(paste0("village_ids_", i))])
  
  #Create bray graph
  assign(
    paste0("bray_vil_graph_", i),
    igraph::simplify(graph_from_adjacency_matrix(
      get(paste0("bray_vil_", i)),
      weighted = TRUE,
      mode = c("undirected")
    ))
  )
  
  #Create bray graph for scrambling
  assign(paste0("bray_vil_graph_scram_", i),
         get(paste0("bray_vil_graph_", i)))  
  
  # #Create jaccard adjacency
  # assign(paste0("jaccard_vil_", i),
  #        species_jaccard_sim[rownames(species_jaccard_sim) %in% get(paste0("village_ids_", i)),
  #                    colnames(species_jaccard_sim) %in% get(paste0("village_ids_", i))])
  # 
  # #Create jaccard graph
  # assign(
  #   paste0("jaccard_vil_graph_", i),
  #   igraph::simplify(graph_from_adjacency_matrix(
  #     get(paste0("jaccard_vil_", i)),
  #     weighted = TRUE,
  #     mode = c("undirected")
  #   ))
  # )
  # 
  # #Create jaccard graph for scrambling
  # assign(paste0("jaccard_vil_graph_scram_", i),
  #        get(paste0("jaccard_vil_graph_", i))) 
  
}

```

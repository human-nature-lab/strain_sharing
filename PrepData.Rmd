---
title: "Untitled"
output: html_notebook
date: "2022-12-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(readr.show_col_types = FALSE) 
```

# Install necessary packages
```{r message=FALSE, warning=FALSE, include=FALSE}
if (!require("readr")) install.packages("readr")
library(readr)
if (!require("stringr")) install.packages("stringr")
library(stringr)
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("igraph")) install.packages("igraph")
library(igraph)
if (!require("vegan")) install.packages("vegan")
library(vegan)
if (!require("compositions")) install.packages("compositions")
library(compositions)
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)
if (!require("lmerTest")) install.packages("lmerTest")
library(lmerTest)
if (!require("pROC")) install.packages("pROC")
library(pROC)
if (!require("ggpubr")) install.packages("ggpubr")
library(ggpubr)
if (!require("svglite")) install.packages("svglite")
library(svglite)
if (!require("ggplotify")) install.packages("ggplotify")
library(ggplotify)
if (!require("mclust")) install.packages("mclust")
library(mclust)
library(tidyr)
library(forcats)
library(doParallel)
```

# Load batch data
```{r message=TRUE, warning=FALSE, include=FALSE}
extraction_batch <- bind_rows(read_csv('~/F_BEGHINI_HM/Rn338 gDNA 032822.csv') |> select(SampleID = `Sample ID`, WIKI = `WIKI ID`, Plate, DNA_conc = `gDNA, ng/uL(Nanodrop)`),
          read_csv('~/F_BEGHINI_HM/Honduras_gDNA_11052020.csv') |> select(SampleID, WIKI, Plate = `gDNA Plate`, DNA_conc = `NanoDrop,ng/uL`),
          read_csv('~/F_BEGHINI_HM/Ejl54 stool WGS 010523.csv') |> select(SampleID, WIKI, Plate = `gDNA Plate`, DNA_conc = `NanoDrop, ng/uL`)) |> 
  mutate( Plate = factor(str_extract(Plate, '[0-9]{6}')),
          WIKI = factor(str_split_i(WIKI, '-', 1)))

sequencing_depth <- bind_rows(
read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ13084_Read_Counts.csv") |> 
  select(SampleID=`Sample ID`, Reads), 

read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ17122_Read_Counts.csv") |> 
  select(SampleID = Sample, Reads = `Read Pairs`), 

read_csv("/WORKAREA/home/fb343/F_BEGHINI_HM/read_counts/RQ19764_Read_Counts.csv") |> 
  select(SampleID=`Sample ID`, Reads)) |> 
  group_by(SampleID) |> 
  summarize(Reads=sum(Reads))

shipping_batch <- 
  read_csv('/WORKAREA/work/HONDURAS_MICROBIOME/F_BEGHINI/COHORT1/v3/hmb_shipments_cohort1_baseline_v3.csv') |> 
  filter(str_detect(barcode, '-05$')) |> 
  select(SampleID=`barcode`, shipment_batch) |> 
  bind_rows(read_csv('/WORKAREA/home/fb343/F_BEGHINI_HM/shipment_batch_cohort2.csv'))

```

```{r}
extraction_batch |> 
  inner_join(sequencing_depth, by = join_by(SampleID)) |> #write_tsv('extraction_sequencing_batch.tsv')
  filter(str_detect(SampleID, '-15', negate=TRUE)) |> 
  arrange(SampleID) |> 
  filter(DNA_conc >= 0) |> 
  mutate(a=1) |> 
  group_by(a) |> 
  summarize(broom::tidy(cor.test(Reads, DNA_conc)))
```

```{r}
king_coeff <- read_tsv('/WORKAREA/work/GENETIC_DATA/HMB/HUMAN/saliva/all_king') |> 
  mutate(
    IID2 = str_remove(IID2, '_*') ,
    `#IID1` = str_remove(`#IID1`, '_*'),
    KINSHIP_RANGE = case_when(
                              KINSHIP > 0.354 ~ 'MZ/duplicate',
                              between(KINSHIP, 0.177, 0.354) ~ '1st deg',
                              between(KINSHIP, 0.0884, 0.177) ~ '2nd deg',
                              between(KINSHIP, 0.0442, 0.0884) ~ '3rd deg'
                              )
) |> arrange(KINSHIP)

```


# Download Microbiome census Data
```{r}

#Microbiome Census Data
hmb_c1 <- read_csv("~/F_BEGHINI_HM/COHORT1/v3/hmb_respondents_cohort1_baseline_v3_f_beghini_2022-11-08.csv", na = c('NA','Dont_Know','Refused'))
hmb_c2 <- read_csv("~/F_BEGHINI_HM/COHORT2/v2/hmb_respondents_cohort2_v2_f_beghini_2022-11-08.csv", na = c('NA','Dont_Know','Refused'))

hmb_c2$mb_m05[is.na(hmb_c2$mb_m05)] <- hmb_c2$mb_m00[is.na(hmb_c2$mb_m05)]
hmb_c2$mb_m05 <- paste0(substr(hmb_c2$mb_m05,0,10), "5")

#One individual was coded incorrectly
hmb_c2$village_code[!is.na(hmb_c2$village_code) & hmb_c2$village_code == 18] <- 17

#Missing certain ones, need to clean that up

master_key <- bind_rows(hmb_c1 |> select(mb_m05, respondent_master_id, village_code),
                  hmb_c2 |> select(mb_m05, respondent_master_id, village_code)
) |> 
  filter(str_detect(mb_m05, 'NA', negate=TRUE))

hmb_census <- bind_rows(hmb_c1,hmb_c2) |> 
  mutate(BMI = (mb_d0100 / mb_d0200 **2) * 10000,
         sampling_date = if_else(is.na(mb_m0100), if_else(!is.na(completed_at_E6), lubridate::as_date(completed_at_E6), lubridate::as_date(completed_at_E5)), mb_m0100))

# Map village id to Spaniard villages
village_map <- tribble(~village_code, ~village_name_deid,
  17 , "Ermua",
  21 , "Azpeitia",
  26 , "Mungia",
  73 , "Tolosa",
  116 , "Basauri",
  144 , "Hondarribia",
  145 , "Hernani",
  162 , "Erandio",
  169 , "Sestao",
  118 , "Bermeo",
  14 , "Getxo",
  41 , "Pasaia",
  140 , "Zarautz",
  89 , "Lekeitio",
  58 , "Laguardia",
  110 , "Zumaia",
  174 , "Getaria",
  5 , "Irun"
)

hmb_census <- full_join(hmb_census, village_map)

#RCT Data
#demographics <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_respondents_WAVE3_v3_F_BEGHINI_2023-10-23.csv")
demographics <- read_csv("/WORKAREA/work/HONDURAS_MICROBIOME/J_PULLMAN/DATA/COHORT_1/v2/honduras_respondents_demographics_J_PULLMAN_2022-11-07.csv", guess_max = 100000) |> 
  select('respondent_master_id','village_code_w3','village_name_w3','building_id_w3', 'household_id_w3', "b0100", "b0200","b0600","b0800","b0900")
```

# Compute Diet Diversity Score
```{r}
hmb_census <- hmb_census |> 
  mutate(across(starts_with('mb_ca'), ~ case_when(as.integer(factor(.x)) / 3 == 1 ~ 1, .default = 0  ))) |>
  mutate(dds_Cereals = as.integer(mb_ca0200|mb_ca0300|mb_ca0400),
         dds_Vegetables = mb_ca1000,
         dds_Fruits = as.integer(mb_ca1100|mb_ca1200),
         dds_Meat_poultry_offal = as.integer(mb_ca1300 |mb_ca1400),
         dds_Eggs = mb_ca0900,
         dds_Fish_seafood = mb_ca1600,
         dds_Legumes = mb_ca0100,
         dds_Dairy = as.integer(mb_ca0500 | mb_ca0600 | mb_ca0700 | mb_ca0800),
         dds_Fats = as.integer(mb_ca1500 | mb_ca1900),
         dds_Sugar = as.integer(mb_ca1700 | mb_ca1800),
         DDS = rowSums(across(starts_with('dds_')))
  )

```

# Load StrainPhlAn data
```{r}
test_ssr_num <- as.matrix(readRDS("data/sharing_rate_with_zero.RDS"))

test_ssr_num <- test_ssr_num[order(rownames(test_ssr_num)),
                             order(colnames(test_ssr_num))]

test_ssr_num <- test_ssr_num[grep('-15', colnames(test_ssr_num), invert = TRUE), grep('-15', colnames(test_ssr_num), invert = TRUE)]

rownames(test_ssr_num) <- master_key$respondent_master_id[match(rownames(test_ssr_num),
                                                            master_key$mb_m05)]
colnames(test_ssr_num) <- master_key$respondent_master_id[match(colnames(test_ssr_num),
                                                                   master_key$mb_m05)]

strain_rate <- test_ssr_num*100
diag(strain_rate) <- 0
strain_rate[is.na(strain_rate)] <- 0
```


# Load MetaPhlAn species data
```{r}
species_data <- readr::read_tsv("data/mpa4_merged_profiles.tsv", skip = 1) |> 
  filter(stringr::str_detect(clade_name, 't__')) |> 
  select(clade_name, ends_with('-05')) |> 
  tibble::column_to_rownames('clade_name') 
species_data <- species_data / 100

# species_data <- species_data[,hmb_census$mb_m05]
colnames(species_data) <- master_key$respondent_master_id[match(colnames(species_data), master_key$mb_m05)]

#Calculate CLR of species relative abundance data
species_data_clr <- species_data
species_data_clr[species_data_clr == 0 ] <- 5e-6
species_data_clr <- clr(species_data_clr)

species_bray <- vegdist(t(species_data), method = "bray")
species_bray <- as.matrix(species_bray)

#Calculate jaccard index manually
species_jaccard_sim <- vegdist(t(species_data), method = 'jaccard', binary=TRUE)
species_jaccard_sim <- as.matrix(species_jaccard_sim)
```

# Calculate coverage rates and update social network to match hmb census
```{r}
#Full edge dataframe
all_edges <- read.csv("/WORKAREA/work/HONDURAS_MICROBIOME/J_PULLMAN/DATA/COHORT_1/v2/honduras_connections_WAVE3_v3_J_PULLMAN_2022-11-07.csv", as.is = TRUE) |> 
              filter(relationship %in% c('child_over12_other_house','closest_friend','father','free_time','mother','partner','personal_private','sibling')) #Remove not get along
#Filter to villages for people we have microbiome information from
all_vils <- hmb_census %>%
  filter(respondent_master_id %in% rownames(strain_rate)) %>%
  dplyr::select(village_code) %>% distinct() %>% pull(village_code)

village_names <- c()
vill_cov = data.frame()
for(i in 1:length(all_vils)){
  vil <- all_edges %>% filter(all_edges$village_code_w3 == all_vils[i])
  vil_ids <- unique(c(vil$ego, vil$alter))
  coverage_rate <- mean(vil_ids %in% rownames(strain_rate))
  num_ppl <- sum(vil_ids %in% rownames(strain_rate))
  vill_cov <- bind_rows(vill_cov,c(village_code = all_vils[i], cov= round(coverage_rate, 3), num_ppl_mb = num_ppl, num_ppl_sn = length(vil_ids)))
  #print(paste(all_vils[i],":", round(coverage_rate, 3), num_ppl, length(vil_ids)))
  if(!is.na(coverage_rate) & coverage_rate >=.3 & num_ppl>=10){
    village_names <- c(village_names, all_vils[i])
  }
}

demographics <- demographics |> filter(village_code_w3 %in% village_names)
```

# Filter edgelist to the villages that with sufficient microbiome coverage
```{r}
all_edges <- all_edges %>%
  filter(village_code_w3 %in% village_names)

all_network_ids <- c(all_edges$ego, all_edges$alter)

#Filter edgelist to study participants who we have microbiome data for
SN <- all_edges %>% filter(ego %in% rownames(strain_rate) , alter %in% rownames(strain_rate))

#Check if people moved villages or houses for whom we have study data for
hmb_census_ego <- hmb_census
names(hmb_census_ego) <- paste0(names(hmb_census_ego),"_ego")
names(hmb_census_ego)[1] <- "ego"
hmb_census_alter <- hmb_census
names(hmb_census_alter) <- paste0(names(hmb_census_alter),"_alter")
names(hmb_census_alter)[1] <- "alter"


SN_census <- merge(SN, hmb_census_ego) %>% merge(hmb_census_alter)
```

# Household data
## Average Household Size from Microbiome Villages
```{r}
demographics %>% group_by(household_id_w3) %>%
  summarise(n = n()) %>% pull(n) %>% mean()
```

```{r}
hmb_census <- hmb_census %>% filter(respondent_master_id %in% rownames(strain_rate),
                                    respondent_master_id %in% all_network_ids)
```

# Get age information

Mean Age: `r round(mean(na.omit(hmb_census$age_at_survey)),2)`, SD `r round(sd(na.omit(hmb_census$age_at_survey)),2)`

Min/Max Age: `r min(na.omit(hmb_census$age_at_survey))` - `r max(na.omit(hmb_census$age_at_survey))`

# Get gender and marriage summary

Percent Female: `r sum(hmb_census$gender == "woman") / nrow(hmb_census)`, Male: `r sum(hmb_census$gender == "man") / nrow(hmb_census)`

`r table(hmb_census$marital_name)/nrow(hmb_census)`

Total Sample Size: `r nrow(hmb_census)`

```{r}
#Use HMB census data and only keep rct data for values we don't have
covariates <- inner_join(hmb_census, demographics, by = join_by(respondent_master_id)) %>%
  dplyr::select(-c("building_id_w3", "village_name_w3"))

covariates$mb_m0300 <- as.factor(str_sub(covariates$mb_m0300, 6, 6))

#Merge on household wealth index data
household_wealth_data4 <- read.csv("~/F_BEGHINI_G/WAVE4/v1/honduras_households_WAVE4_v1_F_BEGHINI_2023-11-01.csv")
household_wealth_data <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_households_WAVE3_v3_F_BEGHINI_2023_10-23.csv")
household_wealth_data2 <- read.csv("~/F_BEGHINI_G/WAVE3/v3/honduras_households_WAVE2_v5_F_BEGHINI_2022-11-01.csv")

household_wealth_data <- household_wealth_data %>% dplyr::select(building_id, l0400, household_wealth_index_w3)
household_wealth_data$l0400 <- as.factor(c('Well with tube' = 1,
'Dug well (proctected)' = 2 ,
'Dug well (unprotected)' = 3 ,
'Water from spring (protected)' = 4 ,
'Water from spring (unproctected)' = 5 ,
'Rainwater' = 6 ,
'Tanker truck' = 7 ,
'Cart with small tank' = 8 ,
'Surface water (river/dam/lake/pond/stream/canal/irrigation channel)'= 9 ,
'bottle water' = 10 ,
'Other' = 11 
)[household_wealth_data$l0400])

#Merge covariates with household wealth data
covariates <- left_join(covariates, household_wealth_data)

covariates[covariates$respondent_master_id=='145q-7f4867c7-a4e1-47e8-9b7c-2d98a4294cdb','household_wealth_index_w3'] <- 5
covariates[covariates$respondent_master_id=='nZno-6b2d0c05-ebeb-464b-836e-31493a161740','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='cPP0-b47b9cbf-eeaf-430a-87bf-d6322e65108b','household_wealth_index_w3'] <- 2
covariates[covariates$respondent_master_id=='nZno-b1e42724-5fd4-4aad-8835-80e8a7f430bf','household_wealth_index_w3'] <- 2
covariates[covariates$respondent_master_id=='enz0-ce7dad59-da03-48d6-9649-40202eba50aa','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='enz0-54c4a166-642d-4707-9dd9-eac58c3452b0','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='cPP0-e7a61fe3-ea87-4f76-b992-bbfbde75393c','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='h4Ru-14c55d32-c61c-44da-9088-6559224a1ae9','household_wealth_index_w3'] <- 3
covariates[covariates$respondent_master_id=='nZno-66d3906b-0036-4943-bfbb-f5aabaa16123','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='cPP0-00ea6c4f-769a-4670-b7af-cc82af90a235','household_wealth_index_w3'] <- 4
covariates[covariates$respondent_master_id=='nZno-50e96e07-ae0e-4be2-a0f3-d45a3308204f','household_wealth_index_w3'] <- 2
covariates[covariates$respondent_master_id=='Obit-d4607866-a62f-4c9a-90b0-0b11db77f970','household_wealth_index_w3'] <- 3
covariates[covariates$respondent_master_id=='/BKO-5f5c3998-40ad-45fa-8430-244a6863c01d','household_wealth_index_w3'] <- 3
covariates[covariates$respondent_master_id=='Ers1-ae8fb0f9-6d87-476c-a9aa-b3c648e35c6a','household_wealth_index_w3'] <- 5
covariates[covariates$respondent_master_id=='enz0-0d3f9285-2398-47e6-aca2-ada2c6a8fc09','household_wealth_index_w3'] <- 3
covariates[covariates$respondent_master_id=='CfVZ-39bb93a1-bbc7-4dad-a261-c3eb047bfe12','household_wealth_index_w3'] <- 1

covariates[covariates$building_id == '8193e681-4079-4b59-a53c-661edb4ebade', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == 'f64acdfd-b9ad-472a-b665-da8e4bd99a7d', 'household_wealth_index_w3']  <-  1
covariates[covariates$building_id == '90991c9e-45f1-48ee-b65f-926d5110e77b', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == 'b509255f-9b80-498d-a1d8-aa00f57bb874', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == '0b74b5c8-5ffa-44fd-b822-fb5bdfbc9947', 'household_wealth_index_w3']  <-  4
covariates[covariates$building_id == '804984d4-2c13-4b43-836e-d8f0b623ea02', 'household_wealth_index_w3']  <-  4
covariates[covariates$building_id == 'aae91e23-5260-4871-944d-c080872d4901', 'household_wealth_index_w3']  <-  4
covariates[covariates$building_id == 'b007fa42-731c-4b11-b990-7bac1e9aed02', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == 'd7b66ef7-664d-48cc-b25d-3c5af12d0146', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == '6f49f077-e8c0-461e-87cb-b5bd69159ff1', 'household_wealth_index_w3']  <-  1
covariates[covariates$building_id == '705b1011-f548-47ac-a791-6a35eb2c55af', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == '45a8a64d-9108-4d35-bc38-345082f1f734', 'household_wealth_index_w3']  <-  4
covariates[covariates$building_id == '4ed14ee9-4d47-498a-9163-b7c79178017a', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == '7da57d60-8887-4a26-83bd-97c72c18fa45', 'household_wealth_index_w3']  <-  2
covariates[covariates$building_id == 'de834381-1898-4542-8937-8e87cbf83075', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == '7f22eea8-daae-4369-9c5f-9d2a25c11a54', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == '2264316c-2a06-4e54-a3aa-c54d71aeb561', 'household_wealth_index_w3']  <-  4
covariates[covariates$building_id == '36a9f122-722f-4a7e-bf9c-ccc1746273e2', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == '4d2e4248-76da-4407-bf7c-ccdefbe27b2e', 'household_wealth_index_w3']  <-  5
covariates[covariates$building_id == '5eff7ec4-e03d-4407-bed6-7a80ff4dffd9', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == '9a74edee-2779-4bd9-8da4-3c1a327f9cee', 'household_wealth_index_w3']  <-  3
covariates[covariates$building_id == 'cd55f742-ddf9-43ba-98ab-a94ef2ead588', 'household_wealth_index_w3']  <-  5

village_centroids <- covariates %>%
  group_by(village_name) %>%
  summarize(
    village_mean_lat = mean(building_latitude),
    village_mean_long = mean(building_longitude)
  )

#Geosphere package too calculate distance in meters
library(geosphere)
village_distances <- distm(village_centroids %>% select(village_mean_lat, village_mean_long),
      fun = distHaversine) /1000
diag(village_distances) <- NA

#Get average distance to closest village
mean(apply(village_distances, MARGIN = 1, FUN = min, na.rm = TRUE))
mean(apply(village_distances, MARGIN = 1, FUN = max, na.rm = TRUE))

covariates <- inner_join(covariates, (hmb_c1 |> select(respondent_master_id, 
med_painkillers = mb_b1100a,
med_antibiotics = mb_b1100b,
med_antidiarrheal = mb_b1100c,
med_antiparasite = mb_b1100d,
med_vitamins = mb_b1100e,
med_zinc = mb_b1100f,
med_antifungal = mb_b1100k) |> bind_rows(
  hmb_c2 |> select(respondent_master_id,
  med_painkillers = mb_b1100a,
  med_antibiotics= mb_b1100b,
  med_antidiarrheal = mb_b1100c,
  med_antiparasite = mb_b1100d,
  med_antifungal = mb_b1100e,
  med_vitamins = mb_b1100f,
  med_antihypertensives = mb_b1100g,
  med_antidiabetics = mb_b1100h,
  med_antiacids = mb_b1100i,
  med_laxatives = mb_b1100j,
  med_zinc = mb_b1100k,
)) |> 
  mutate(across(-respondent_master_id, ~if_else(is.na(.x), 0, 1)))))
```


# Finish Processing social network data
```{r}
SN_census <- SN_census %>% select(-c("village_name_ego", "village_name_alter", "same_building"))
names(SN_census)[names(SN_census) == "same_building_updated"] <- "same_building"
SN <- SN_census


strain_rate <- strain_rate[rownames(strain_rate) %in% rownames(species_bray),
                           colnames(strain_rate) %in% rownames(species_bray)]




#Create unique pair identifier
for(i in 1:nrow(SN)){
  combo <- paste0(SN$ego[i], SN$alter[i])
  SN$pair_key[i] <- paste((sort(str_split(combo,"")[[1]])),sep="", collapse="")
}





#add on microbiome sharing data
for(i in 1:nrow(SN)){
  if(!is.na(strain_rate[rownames(strain_rate) == SN$ego[i],colnames(strain_rate) == SN$alter[i]])){
    SN$strain_sharing_rate[i] <- strain_rate[rownames(strain_rate) == SN$ego[i],
                                           colnames(strain_rate) == SN$alter[i]]
  }
  else{
    SN$strain_sharing_rate[i] <- strain_rate[rownames(strain_rate) == SN$alter[i],
                                           colnames(strain_rate) == SN$ego[i]]
  }
  
}

SN$strain_sharing_rate[is.na(SN$strain_sharing_rate)] <- 0

#Filter social network data data to who we also have microbiome data for
SN <- SN[SN$ego %in% rownames(strain_rate) & SN$alter %in% rownames(strain_rate),]

for(i in 1:nrow(SN)){
  SN$bray_curtis_sim[i] <- species_bray[rownames(species_bray) == SN$ego[i],
                                           colnames(species_bray) == SN$alter[i]]
}

for(i in 1:nrow(SN)){
  SN$jaccard_sim[i] <- species_jaccard_sim[rownames(species_jaccard_sim) == SN$ego[i],
                                           colnames(species_jaccard_sim) == SN$alter[i]]
}

#Filter Microbiome data to who we also have social network data for
strain_rate <- strain_rate[rownames(strain_rate) %in% unique(c(SN$ego, SN$alter)),
                           colnames(strain_rate) %in% unique(c(SN$ego, SN$alter))]

#Filter covariates to individuals we also have social network data for
covariates <- covariates[covariates$respondent_master_id %in% unique(c(SN$ego, SN$alter)),]

#Changes names of relationship variable
rename_relationship_table <- c(child_over12_other_house = "Child",
                               closest_friend = "Closest Friend",
                               father = "Father",
                               free_time = "Spend Free Time",
                               mother = "Mother",
                               partner = "Partner",
                               personal_private = "Personal or Private Relationship",
                               sibling = "Sibling")

SN$relationship <- as.character(rename_relationship_table[SN$relationship])
```

# Get counts of unique relationships

SN %>% distinct(pair_key, relationship) %>%
  group_by(relationship) %>% summarize(n = n()) %>% arrange(n)

Total count of nominations: `r SN %>% distinct(pair_key) %>% nrow()`


# Average number of nominations
SN %>%
  group_by(pair_key) %>%
  mutate(n = n()) %>%
  ungroup() %>%
  distinct(pair_key, .keep_all = TRUE) %>%
  pull(n) %>%
  mean()

# Get list of pairs that are kin or living in the same house
```{r}
family_house_pairs <- unique(SN$pair_key[SN$building_id_alter == SN$building_id_ego |
                                           SN$relationship %in% c("father", "mother", "sibling", "child_over12_other_house")])

SN_full_directed_graph <- graph_from_data_frame(SN)
mutual_conns <- which_mutual(SN_full_directed_graph)
SN_mutual_conns <- subgraph.edges(SN_full_directed_graph, E(SN_full_directed_graph)[mutual_conns])
```

# Create helpful datasets at the village level
```{r}
#Create auxiliary networks

for(i in 1:nrow(all_edges)){
  combo <- paste0(all_edges$ego[i], all_edges$alter[i])
  all_edges$pair_key[i] <- paste((sort(str_split(combo,"")[[1]])),sep="", collapse="")
}

for(i in 1:length(village_names)){
  #Create social networks edge lists
  assign(paste0("sn_vil_", i), SN %>% filter(village_code_w3 == village_names[i]))
  
  assign(paste0("sn_vil_all_", i), all_edges %>% filter(village_code_w3 == village_names[i]))
  
  #Create social network graphs
  assign(paste0("sn_vil_graph_", i),
         igraph::simplify(graph_from_data_frame(get(paste0("sn_vil_", i)),
                                                                            directed = FALSE)))
  
  assign(paste0("sn_vil_graph_all_", i),
         igraph::simplify(graph_from_data_frame(get(paste0("sn_vil_all_", i)),
                                                                            directed = FALSE)))
  
  #Create social network graphs for scrambling
  assign(paste0("sn_vil_graph_scram_", i), get(paste0("sn_vil_graph_", i)))
  
  #Create village id Vectors
  assign(paste0("village_ids_", i),
         unique(c(get(paste0("sn_vil_", i))$ego , get(paste0("sn_vil_", i))$alter)))
  
  #Create strain sharing rate adjacency
  assign(paste0("strain_rate_vil_", i),
         strain_rate[rownames(strain_rate) %in% get(paste0("village_ids_", i)),
                     colnames(strain_rate) %in% get(paste0("village_ids_", i))])
  
  #Create strain sharing rate graph
  assign(
    paste0("strain_rate_vil_graph_", i),
    igraph::simplify(graph_from_adjacency_matrix(
      get(paste0("strain_rate_vil_", i)),
      weighted = TRUE,
      mode = c("undirected")
    ))
  )
  
  #Create strain sharing rate graph for scrambling
  assign(paste0("strain_rate_vil_graph_scram_", i),
         get(paste0("strain_rate_vil_graph_", i)))
  
  
  #Create bray adjacency
  assign(paste0("bray_vil_", i),
         species_bray[rownames(species_bray) %in% get(paste0("village_ids_", i)),
                     colnames(species_bray) %in% get(paste0("village_ids_", i))])
  
  #Create bray graph
  assign(
    paste0("bray_vil_graph_", i),
    igraph::simplify(graph_from_adjacency_matrix(
      get(paste0("bray_vil_", i)),
      weighted = TRUE,
      mode = c("undirected")
    ))
  )
  
  #Create bray graph for scrambling
  assign(paste0("bray_vil_graph_scram_", i),
         get(paste0("bray_vil_graph_", i)))  
  
  # #Create jaccard adjacency
  # assign(paste0("jaccard_vil_", i),
  #        species_jaccard_sim[rownames(species_jaccard_sim) %in% get(paste0("village_ids_", i)),
  #                    colnames(species_jaccard_sim) %in% get(paste0("village_ids_", i))])
  # 
  # #Create jaccard graph
  # assign(
  #   paste0("jaccard_vil_graph_", i),
  #   igraph::simplify(graph_from_adjacency_matrix(
  #     get(paste0("jaccard_vil_", i)),
  #     weighted = TRUE,
  #     mode = c("undirected")
  #   ))
  # )
  # 
  # #Create jaccard graph for scrambling
  # assign(paste0("jaccard_vil_graph_scram_", i),
  #        get(paste0("jaccard_vil_graph_", i))) 
  
}

```
```{r}
library(tableone)

myvars <- c('age_at_survey', 'gender','marital_name')

demographics %>% group_by(household_id_w3) %>%
  summarise(n = n()) %>% pull(n) %>% mean()
  
all_tableone <- CreateTableOne(data = hmb_census, strata = 'village_name_deid', vars = myvars, test = FALSE, addOverall = TRUE, )
rel_tableone <- CreateTableOne(data = distinct(SN, pair_key, relationship, .keep_all = TRUE), strata = 'village_name_deid_ego', vars = 'relationship', test = FALSE, addOverall = TRUE, )
wlt_tableone_mat <- print(CreateTableOne(data = covariates, strata = 'village_name_deid', vars = c('DDS', 'household_wealth_index_w3'), test = FALSE, addOverall = TRUE, ), printToggle = FALSE)[]

rel_tableone_mat <- (print(rel_tableone, printToggle = FALSE, format = 'f'))
rel_tableone_mat[2,] <- rel_tableone_mat[1,]
rel_tableone_mat <- rel_tableone_mat[-1,]
rownames(rel_tableone_mat)[1] <- 'Relationship (n=)'
write.csv(as.data.frame(rbind((print(all_tableone, printToggle = FALSE)), rel_tableone_mat, wlt_tableone_mat)), 'tables/tableone.csv', )


```
---
title: "Centrality_Species_Correlations"
author: "Jackson Pullman"
date: "2023-01-25"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Calculate Centralities for the network with microbiome
```{r}
for(i in 1:length(village_names)){
  sn_vil <- SN %>% filter(village_name_w3 == village_names[i])
  village_ids <- unique(c(sn_vil$ego, sn_vil$alter))
  sn_vil <- simplify(graph_from_data_frame(sn_vil, directed = FALSE))
  crossclique_vil <- centiserve::crossclique(sn_vil)
  eigen_vil <- eigen_centrality(sn_vil)$vector
  between_vil <- igraph::betweenness(sn_vil, normalized = TRUE)
  degree_vil <- igraph::degree(sn_vil)
  if(i == 1){
    centrality_df <- data.frame(respondent_master_id = names(V(sn_vil)),
                                crossclique_c = unname(crossclique_vil),
                                eigen_c = unname(eigen_vil),
                                between_c = unname(between_vil),
                                degree_c = unname(degree_vil),
                                village = rep(village_names[i], length(crossclique_vil))
                                )
  }
  else{
    centrality_df <- rbind(centrality_df,
                                       data.frame(respondent_master_id = names(V(sn_vil)),
                                                  crossclique_c = unname(crossclique_vil),
                                                  eigen_c = unname(eigen_vil),
                                                  between_c = unname(between_vil),
                                                  degree_c = unname(degree_vil),
                                                  village = rep(village_names[i],
                                                                length(crossclique_vil))
                                       ))
  }
}
```


Calculate Centralities for the whole (even without microbiome)
```{r}
for(i in 1:length(village_names)){
  sn_vil <- all_edges %>% filter(village_name_w3 == village_names[i])
  village_ids <- unique(c(sn_vil$ego, sn_vil$alter))
  sn_vil <- simplify(graph_from_data_frame(sn_vil, directed = FALSE))
  crossclique_vil <- centiserve::crossclique(sn_vil)
  eigen_vil <- eigen_centrality(sn_vil)$vector
  between_vil <- igraph::betweenness(sn_vil, normalized = TRUE)
  degree_vil <- igraph::degree(sn_vil)
  if(i == 1){
    centrality_df_all <- data.frame(respondent_master_id = names(V(sn_vil)),
                                crossclique_c = unname(crossclique_vil),
                                eigen_c = unname(eigen_vil),
                                between_c = unname(between_vil),
                                degree_c = unname(degree_vil),
                                village = rep(village_names[i], length(crossclique_vil))
                                )
  }
  else{
    centrality_df_all <- rbind(centrality_df_all,
                                       data.frame(respondent_master_id = names(V(sn_vil)),
                                                  crossclique_c = unname(crossclique_vil),
                                                  eigen_c = unname(eigen_vil),
                                                  between_c = unname(between_vil),
                                                  degree_c = unname(degree_vil),
                                                  village = rep(village_names[i],
                                                                length(crossclique_vil))
                                       ))
  }
}

centrality_df_all <- centrality_df_all %>%
  filter(respondent_master_id %in% centrality_df$respondent_master_id)

dim(centrality_df_all)
dim(centrality_df)

#Order
centrality_df_all <- centrality_df_all[match(centrality_df$respondent_master_id,
                                             centrality_df_all$respondent_master_id),]



```

Trichotomize networks
```{r}
#Trichotomize microbiomenetwork
centrality_df_tri <- centrality_df %>%
  group_by(village) %>%
  mutate(eigen_tri = case_when(
    eigen_c >= quantile(eigen_c, .66) ~ "Popular",
    eigen_c <= quantile(eigen_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  between_tri = case_when(
    between_c >= quantile(between_c, .66) ~ "Popular",
    between_c <= quantile(between_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  degree_tri = case_when(
    degree_c >= quantile(degree_c, .66) ~ "Popular",
    degree_c <= quantile(degree_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  )) %>%
  ungroup() %>%as.data.frame()

#Trichotomize full
centrality_df_tri_all <- centrality_df_all %>%
  group_by(village) %>%
  mutate(eigen_tri = case_when(
    eigen_c >= quantile(eigen_c, .66) ~ "Popular",
    eigen_c <= quantile(eigen_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  between_tri = case_when(
    between_c >= quantile(between_c, .66) ~ "Popular",
    between_c <= quantile(between_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  degree_tri = case_when(
    degree_c >= quantile(degree_c, .66) ~ "Popular",
    degree_c <= quantile(degree_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  )) %>%
  ungroup() %>%as.data.frame()
```




See how network is order based on Eigenvector centrality
```{r}
for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  eigen_tri == "Popular")
  mid_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  eigen_tri == "Middle")
  iso_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  eigen_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.2)) +
    stat_compare_means(label.y = .2) +
    ggtitle(village_names[i]) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}


means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.2)) +
  stat_compare_means(label.y = .2) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (centrality|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)
```


Betwenness centrality
```{r}

for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Popular")
  mid_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Middle")
  iso_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.35)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Betweenness")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

?stat_compare_means
means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)
#Ok I'm almost ready to believe this, what about degree centrality
```

Degree Centrality
```{r}

for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  degree_tri == "Popular")
  mid_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  degree_tri == "Middle")
  iso_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  degree_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.35)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Degree")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)

```

eigen full network
```{r}
for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  eigen_tri == "Popular")
  mid_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  eigen_tri == "Middle")
  iso_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  eigen_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.35)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Eigen")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)
```

I believe this holds at the village level, maybe because of some degree assortativity. May want to control for this somehow. 

Check if it holds across all villages
```{r}
#Get counts across for individuals in different villages
#Remove people in the same village
#This could also be an effect of village size here
strain_2_rate <- strain_rate

for(i in 1:length(village_names)){
  SN_Village <- SN %>% filter(village_name_w3 == village_names[i])
  village_ids <- unique(c(SN_Village$ego, SN_Village$alter))
  for(j in 1:length(village_ids)-1){
    for(k in j:length(village_ids)){
      strain_2_rate[rownames(strain_2_rate) == village_ids[j] , colnames(strain_2_rate) == village_ids[k]] <- NA
      strain_2_rate[colnames(strain_2_rate) == village_ids[j] , rownames(strain_2_rate) == village_ids[k]] <- NA
    }
  }
}

pop_vil <- centrality_df_tri_all %>% filter(eigen_tri == "Popular")
mid_vil <- centrality_df_tri_all %>% filter(eigen_tri == "Middle")
iso_vil <- centrality_df_tri_all %>% filter(eigen_tri == "Isolated")

pop_vil_sim <- strain_2_rate[rownames(strain_2_rate) %in% pop_vil$respondent_master_id,
                           colnames(strain_2_rate) %in% pop_vil$respondent_master_id]

pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA

pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))

mid_vil_sim <- strain_2_rate[rownames(strain_2_rate) %in% mid_vil$respondent_master_id,
                           colnames(strain_2_rate) %in% mid_vil$respondent_master_id]

mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))

iso_vil_sim <- strain_2_rate[rownames(strain_2_rate) %in% iso_vil$respondent_master_id,
                           colnames(strain_2_rate) %in% iso_vil$respondent_master_id]

iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))


temp <- data.frame(similarity = c(pop_vil_sim,
                                  mid_vil_sim,
                                  iso_vil_sim),
                   centrality = c(rep("Popular", length(pop_vil_sim)),
                                  rep("Middle", length(mid_vil_sim)),
                                  rep("Isolated", length(iso_vil_sim))))

means_central <- aggregate(similarity ~  centrality, temp, mean)

p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                        c("Middle", "Popular"),
                                        c("Isolated", "Popular")),
                     label.y = c(.2, .3, .25)) +
  ggtitle(paste0(village_names[i], " Eigen")) +
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))

print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = temp)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)

#Popular people still more similar at the strain level than isolated people, what if we remove people in the same village

#Effect is lower but still significant
#Socially isolated people are always microbially distinct. That's an interesting finding. 
#I want to do some within village MDS here

```


Betweenness full network
```{r}
for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  between_tri == "Popular")
  mid_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  between_tri == "Middle")
  iso_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  between_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.35)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Betweenness")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)
```



Degree with full network
```{r}
for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Popular")
  mid_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Middle")
  iso_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Isolated")
  
  pop_vil_sim <- strain_rate[rownames(strain_rate) %in% pop_vil$respondent_master_id,
                             colnames(strain_rate) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- strain_rate[rownames(strain_rate) %in% mid_vil$respondent_master_id,
                             colnames(strain_rate) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- strain_rate[rownames(strain_rate) %in% iso_vil$respondent_master_id,
                             colnames(strain_rate) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,.35)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Degree")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.35)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)
```


Same for Jaccard Similarity

```{r}

for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Popular")
  mid_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Middle")
  iso_vil <- centrality_df_tri_all %>% filter(village == village_names[i],
                                                  degree_tri == "Isolated")
  
  pop_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% pop_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% mid_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% iso_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,1)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Degree")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,1)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.015)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)

#Wild wtf is going on here
```


```{r}
for(i in 1:length(village_names)){
  pop_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Popular")
  mid_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Middle")
  iso_vil <- centrality_df_tri %>% filter(village == village_names[i],
                                                  between_tri == "Isolated")
  
  pop_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% pop_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% pop_vil$respondent_master_id]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% mid_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% mid_vil$respondent_master_id]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% iso_vil$respondent_master_id,
                             colnames(species_jaccard_sim) %in% iso_vil$respondent_master_id]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot(outlier.shape = NA) +
    coord_cartesian(ylim = c(0,1)) +
    stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
    ggtitle(paste0(village_names[i], " Degree")) +
    geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, median)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,1)) +
  stat_compare_means(comparisons = list(c("Isolated", "Middle"),
                                          c("Middle", "Popular"),
                                          c("Isolated", "Popular")),
                       label.y = c(.2, .3, .25)) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.015)) 
  
print(p)

#Let's try lmer model to account for this
test_mod <- lmerTest::lmer(similarity ~ centrality + (1|village), data = pop_iso_sim_df)
#Popular people are more similar at the strain level, but not necessarily middle compared to the rest
summary(test_mod)


#Not convinced this hold up for species, it probably doesn't

#I am convinced that it holds up for strains
#Can potentially report the strain model
#An anova visualization would be beautiful
#Maybe just control for degree assortativity
#Report the two results

```





Within Village MDS
```{r}
#Let's try NMDS here
i<- 1

for( i in 1:length(village_names)){
  vil_ids <- centrality_df_tri_all %>%
    filter(village == village_names[i]) %>%
    pull(respondent_master_id)
  strain_vil <- strain_rate[rownames(strain_rate) %in% vil_ids,
                            colnames(strain_rate) %in% vil_ids]
  
  #strain_vil[42,4]
  strain_vil <- 1-strain_vil
  strain_vil[strain_vil == 0] <- .0001
  diag(strain_vil) <- 0
  
  my_nmds <- MASS::isoMDS(strain_vil)
  
  # print the new coordinates for each city
  my_nmds <- as.data.frame(my_nmds$points)
  my_nmds$centrality <- centrality_df_tri_all$eigen_tri[match(rownames(my_nmds),
                                                              centrality_df_tri_all$respondent_master_id)]
  
  names(my_nmds) <- c("NMDS_1", "NMDS_2", "Centrality")
  
  my_nmds$Centrality <-as.factor(my_nmds$Centrality)
  
  
  p2 <- ggplot(my_nmds, aes(x = NMDS_1, y = NMDS_2, color = Centrality)) +
    geom_point() +
    ggtitle("NMDS of Strain-Sharing Rate") +
    scale_colour_manual(values = c("red", "blue", "darkgreen")) +
    stat_ellipse()
  
  print(p2)
}


```


Within village PCoA

```{r}
?stats::cmdscale
?match


# import the stats package
for( i in 1:length(village_names)){
  vil_ids <- centrality_df_tri_all %>%
    filter(village == village_names[i]) %>%
    pull(respondent_master_id)
  strain_vil <- strain_rate[rownames(strain_rate) %in% vil_ids,
                            colnames(strain_rate) %in% vil_ids]
  
  #strain_vil[42,4]
  strain_vil <- 1-strain_vil
  #strain_vil[strain_vil == 0] <- .0001
  diag(strain_vil) <- 0
  
  my_pcoa <- stats::cmdscale(strain_vil)
  
  my_pcoa <- as.data.frame(my_pcoa)
  
  my_pcoa$centrality <- centrality_df_tri_all$eigen_tri[match(rownames(my_pcoa),
                                                              centrality_df_tri_all$respondent_master_id)]
  
  names(my_pcoa) <- c("PCoA_1", "PCoA_2", "Centrality")
  
  my_pcoa$Centrality <-as.factor(my_pcoa$Centrality)
  
  
  p2 <- ggplot(my_pcoa, aes(x = PCoA_1, y = PCoA_2, color = Centrality)) +
    geom_point() +
    ggtitle("PCoA of Strain-Sharing Rate") +
    scale_colour_manual(values = c("red", "blue", "darkgreen")) +
    stat_ellipse()
  
  print(p2)
}





```

Test t-Sne


```{r}
for( i in 1:length(village_names)){
  vil_ids <- centrality_df_tri_all %>%
    filter(village == village_names[i]) %>%
    pull(respondent_master_id)
  strain_vil <- strain_rate[rownames(strain_rate) %in% vil_ids,
                            colnames(strain_rate) %in% vil_ids]
  
  strain_vil <- 1-strain_vil
  diag(strain_vil) <- 0
  demo.tsne <- tsne(as.dist(strain_vil),k=2,perplexity=10)
  demo.tsne <- as.data.frame(demo.tsne$points)

  rownames(demo.tsne) <- rownames(strain_vil)
  
  demo.tsne$Centrality <- centrality_df_tri_all$eigen_tri[match(rownames(demo.tsne),
                                                              centrality_df_tri_all$respondent_master_id)]

  names(demo.tsne) <- c("t_SNE_1", "t_SNE_2", "Centrality")
  
  demo.tsne$Centrality <-as.factor(demo.tsne$Centrality)
  
  
  p2 <- ggplot(demo.tsne, aes(x = t_SNE_1, y = t_SNE_2, color = Centrality)) +
    geom_point() +
    ggtitle("t-SNE of Strain-Sharing Rate") +
    scale_colour_manual(values = c("red", "blue", "darkgreen")) +
    stat_ellipse()
  
  print(p2)
}

#Maybe some stuff with t-SNE here
```



Could also do this to pick up on social network commmunities
```{r}
install.packages('M3C')
library(M3C)
data(pollen)
tsne(pollen$data,colvec=c('gold'))

install.packages('Rtsne')
library(Rtsne)
?Rtsne

library(labdsv)

demo.tsne <- tsne(as.dist(strain_vil),k=2)
dim(strain_vil)
demo.tsne <- demo.tsne$points
demo.tsne <- as.data.frame(demo.tsne)
rownames(demo.tsne) <- rownames(strain_vil)

demo.tsne$centrality <- centrality_df_tri_all$eigen_tri[match(rownames(demo.tsne),
                                                              centrality_df_tri_all$respondent_master_id)]

p2 <- ggplot(demo.tsne, aes(x = V1, y = V2, color = centrality)) +
    geom_point() +
    ggtitle("t-SNE of Strain-Sharing Rate") +
    scale_colour_manual(values = c("red", "blue", "darkgreen")) +
    stat_ellipse()

p2

```


Average centrality of each species
```{r}
dim(centrality_df_all)

species_data_centrality <- species_data_filt
species_data_centrality <- t(species_data_centrality)
species_data_centrality <- species_data_centrality[match(centrality_df_all$respondent_master_id,
                                                         rownames(species_data_centrality)),]

species_data_centrality[species_data_centrality>0]<-1
species_data_centrality[species_data_centrality == 0] <- NA

species_data_centrality <- species_data_centrality[,colSums(species_data_centrality,
                                                             na.rm = TRUE) >=10]

#Take species in less than 100 people
most_prevalent <- colSums(species_data_centrality, na.rm = TRUE) >=50

sum(!most_prevalent)

species_betweenness <- species_data_centrality
for(i in 1:ncol(species_betweenness)){
  species_betweenness[,i] <- species_betweenness[,i] * centrality_df_all$between_c
}
#species_betweenness[species_betweenness == 0] <- NA
species_betweenness <- colMeans(species_betweenness, na.rm = TRUE)
#hist(species_betweenness, breaks = 100)

df <- data.frame(avg_centrality = unname(species_betweenness),
                 species_name = names(species_betweenness),
                 highly_prevalent = most_prevalent)

wilcox.test(avg_centrality~highly_prevalent, data = df)

ggplot(df, aes(x=avg_centrality, color=highly_prevalent)) +
  geom_histogram(position="identity",fill="white", alpha=0.5)


species_eigen <- species_data_centrality
for(i in 1:ncol(species_eigen)){
  species_eigen[,i] <- species_eigen[,i] * centrality_df_all$eigen_c
}

species_eigen <- colMeans(species_eigen, na.rm = TRUE)


df <- data.frame(avg_centrality = unname(species_eigen),
                 species_name = names(species_eigen),
                 highly_prevalent = most_prevalent)

wilcox.test(avg_centrality~highly_prevalent, data = df)

ggplot(df, aes(x=avg_centrality)) +
  geom_histogram(position="identity")
#Intersting, not highly prevalent are more extreme. 

species_degree <- species_data_centrality
for(i in 1:ncol(species_degree)){
  species_degree[,i] <- species_degree[,i] * centrality_df_all$degree_c
}
#species_degree[species_eigen == 0] <- NA
species_degree <- colMeans(species_degree, na.rm = TRUE)
hist(species_degree, breaks = 100)
#Color by average abundance?

df <- data.frame(avg_centrality = unname(species_degree),
                 species_name = names(species_degree),
                 highly_prevalent = most_prevalent)

wilcox.test(avg_centrality~highly_prevalent, data = df)

ggplot(df, aes(x=avg_centrality, color=highly_prevalent)) +
  geom_histogram(position="identity",fill="white", alpha=0.5)

sum(most_prevalent)

mean(df %>% filter(highly_prevalent) %>% pull(avg_centrality))

mean(df %>% filter(!highly_prevalent) %>% pull(avg_centrality))
#I think that it's higher just because it's not bounded on top




h <- hist(species_degree, breaks = 100)
xfit <- seq(min(species_degree), max(species_degree), length = 40) 
yfit <- dnorm(xfit, mean = mean(species_degree), sd = sd(species_degree)) 
yfit <- yfit * diff(h$mids[1:2]) * length(species_degree) 

lines(xfit, yfit, col = "black", lwd = 2)

#Sharper peaked because it's collection of averages

```



Maaslin appraoch
```{r}
if(!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("Maaslin2")
```

```{r}
getwd()
dir.create("R_Maaslin_tutorial") # Create a new directory
setwd("R_Maaslin_tutorial") # Change the current working directory 
getwd() #check if directory has been successfully changed

#Load MaAsLin 2 package into the R environment
library(Maaslin2)
?Maaslin2
```

```{r}
input_data = system.file(
    "extdata", "HMP2_taxonomy.tsv", package="Maaslin2") # The abundance table file
input_data
input_metadata = system.file(
    "extdata", "HMP2_metadata.tsv", package="Maaslin2") # The metadata table file
input_metadata

df_input_data = read.table(file = input_data, header = TRUE, sep = "\t",
                            row.names = 1,
                            stringsAsFactors = FALSE)
df_input_data[1:5, 1:5]
df_input_metadata = read.table(file = input_metadata, header = TRUE, sep = "\t",
                                row.names = 1,
                                stringsAsFactors = FALSE)
df_input_metadata[1:5, ]

fit_data = Maaslin2(input_data     = input_data, 
                    input_metadata = input_metadata, 
                    min_prevalence = 0,
                    normalization  = "NONE",
                    output         = "demo_output", 
                    fixed_effects  = c("diagnosis", "dysbiosis"),
                    reference      = c("diagnosis,nonIBD"))

#My metadata will include covariates and the centrality metric
#Include random effect at the village level
#Can dichotomize into the top quartile and bottom quartile



species_data[1:5,1:5]

df_input_data[1:5, 1:5]

#Rownames don't need to line up, sick


for(i in 1:length(village_names)){
  sn_vil <- SN %>% filter(village_name_w3 == village_names[i])
  village_ids <- unique(c(sn_vil$ego, sn_vil$alter))
  sn_vil <- simplify(graph_from_data_frame(sn_vil, directed = FALSE))
  crossclique_vil <- centiserve::crossclique(sn_vil)
  eigen_vil <- eigen_centrality(sn_vil)$vector
  between_vil <- igraph::betweenness(sn_vil, normalized = TRUE)
  degree_vil <- igraph::degree(sn_vil)
  if(i == 1){
    centrality_df <- data.frame(respondent_master_id = names(V(sn_vil)),
                                crossclique_c = unname(crossclique_vil),
                                eigen_c = unname(eigen_vil),
                                between_c = unname(between_vil),
                                degree_c = unname(degree_vil),
                                village = rep(village_names[i], length(crossclique_vil))
                                )
  }
  else{
    centrality_df <- rbind(centrality_df,
                                       data.frame(respondent_master_id = names(V(sn_vil)),
                                                  crossclique_c = unname(crossclique_vil),
                                                  eigen_c = unname(eigen_vil),
                                                  between_c = unname(between_vil),
                                                  degree_c = unname(degree_vil),
                                                  village = rep(village_names[i],
                                                                length(crossclique_vil))
                                       ))
  }
}

df_input_metadata[1:5, ]
centrality_df[1:5,]

rownames(centrality_df) <- centrality_df$respondent_master_id

centrality_df <- centrality_df %>% select(-c("respondent_master_id"))

names(centrality_df)

sum(is.na(centrality_df$village))

dim(species_data_filt)

#maybe want to filter to most prevalent species
dim(species_data)
species_data_filt <- species_data[rownames(species_data) %in% rownames(centrality_df),]

fit_data2 = Maaslin2(input_data     = species_data_filt, 
                     input_metadata = centrality_df, 
                     min_prevalence = 0,
                     normalization  = "CLR",
                     transform = "NONE",
                     output         = "demo_output2", 
                     fixed_effects  = c("between_c", "eigen_c", "degree_c"),
                     random_effects = c("village"),
                     plot_heatmap = TRUE,
                     heatmap_first_n = 50,
                     cores = 2)


str(fit_data2)
?grepl
colnames(species_data_filt)[grepl("Kluyvera_intermedia",colnames(species_data_filt))]

parallel::detectCores()
#Maybe adding in controls will give me more confidence
#Some sort of added variable plot instead
#Permanova instead would make more sense
#How to see difference across vilages
#See if vilalge level groupings is important
#Talk more with Shiv, even if he won't help
#Setting abundance threshold? I think RI is bad, should dichotomize if anything
```

Back to anova
```{r}
species_bray[1:5,1:5]

species_data_filt_degree[1:5,1:5]
dim(species_data_filt_degree)
centrality_df_quart_degree$degree_quart

#May want to split up by village
species_data_filt_degree_dist <- vegan::vegdist(t(species_data_filt_degree), method = "bray")

degree_mds <- vegan::metaMDS(species_data_filt_degree_dist, distance = "bray")
degree_mds_metadata <- degree_mds$points %>% as_tibble()
degree_mds_metadata$centrality <- centrality_df_quart_degree$degree_quart 

degree_mds_metadata %>%
  ggplot(aes(x = MDS1, y = MDS2, color = centrality)) +
  geom_point() +
  stat_ellipse()

species_data_filt_eigen_dist <- vegan::vegdist(t(species_data_filt_eigen), method = "bray")

eigen_mds <- vegan::metaMDS(species_data_filt_eigen_dist, distance = "bray")
eigen_mds_metadata <- eigen_mds$points %>% as_tibble()
eigen_mds_metadata$centrality <- centrality_df_quart_eigen$eigen_quart 

eigen_mds_metadata %>%
  ggplot(aes(x = MDS1, y = MDS2, color = centrality)) +
  geom_point() +
  stat_ellipse()

species_data_filt_between_dist <- vegan::vegdist(t(species_data_filt_between), method = "bray")

between_mds <- vegan::metaMDS(species_data_filt_between_dist, distance = "bray")
between_mds_metadata <- between_mds$points %>% as_tibble()
between_mds_metadata$centrality <- centrality_df_quart_between$between_quart 

between_mds_metadata %>%
  ggplot(aes(x = MDS1, y = MDS2, color = centrality)) +
  geom_point() +
  stat_ellipse()



?metaMDS
rownames(centrality_df_quart_degree) == rownames(degree_mds$points)



#May want to split up by village
for(i in 1:9){
  vil_vec <- centrality_df_quart_degree$village == village_names[i]
  vil_central <- centrality_df_quart_degree[vil_vec,]
  
  species_dat_vil <- t(species_data_filt_degree)
  species_dat_vil <- species_dat_vil[vil_vec,]
  
  species_data_filt_degree_dist <- as.matrix(vegan::vegdist(species_dat_vil, method = "jaccard"),
                                             nrow = nrow(species_dat_vil))

  degree_mds <- vegan::metaMDS(as.dist(species_data_filt_degree_dist))
  degree_mds_metadata <- degree_mds$points %>% as_tibble()
  degree_mds_metadata$centrality <- vil_central$degree_quart 
  
  p <- degree_mds_metadata %>%
    ggplot(aes(x = MDS1, y = MDS2, color = centrality)) +
    geom_point() +
    stat_ellipse() +
    ggtitle(village_names[i])
  
  print(p)
}

test_adonis <- vegan::adonis(species_data_filt_degree_dist ~ vil_central$degree_quart,
                             permutations = 9999)

#Maybe I do want to use all around centrality. To run next. Use setup from the video, run thorugh all villages by themselves and all villages together
test_adonis$aov.tab$`Pr(>F)`[1]

```



Jaccard Level
```{r}
species_jaccard <- species_data
species_jaccard[species_jaccard>0] <- 1
species_jaccard[1:5,1:5]
jaccard_overlap <- species_jaccard %*% t(species_jaccard)

jaccard_denom <- matrix(data = NA, nrow = nrow(jaccard_overlap), ncol = nrow(jaccard_overlap))

for(i in 1:nrow(species_jaccard)){
  for(j in i:nrow(species_jaccard)){
    temp_row <- species_jaccard[i,] + species_jaccard[j,]
    jaccard_denom[i,j] <- sum(temp_row >0)
  }
  print(i)
}

jaccard_overlap[1:5,1:5]
jaccard_denom[1:5,1:5]
species_jaccard_sim <- jaccard_overlap/jaccard_denom

rownames(species_jaccard_sim) <- rownames(species_jaccard)

#Make symmetric
for(i in 1:(nrow(species_jaccard_sim)-1)){
  for(j in (i+1):nrow(species_jaccard_sim)){
    species_jaccard_sim[j,i] <- species_jaccard_sim[i,j]
  }
}
species_jaccard_sim[1:5,1:5]
```



```{r}

for(i in 1:length(village_names)){
  pop_vil <- centrality_df_quart %>% filter(village == village_names[i],
                                                  eigen_tri == "Popular")
  mid_vil <- centrality_df_quart %>% filter(village == village_names[i],
                                                  eigen_tri == "Middle")
  iso_vil <- centrality_df_quart %>% filter(village == village_names[i],
                                                  eigen_tri == "Isolated")
  
  pop_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(pop_vil),
                             colnames(species_jaccard_sim) %in% rownames(pop_vil)]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  mid_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(mid_vil),
                             colnames(species_jaccard_sim) %in% rownames(mid_vil)]
  
  mid_vil_sim[lower.tri(mid_vil_sim, diag = TRUE)] <- NA

  mid_vil_sim <- na.omit(unlist(as.list(mid_vil_sim)))
  
  iso_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(iso_vil),
                             colnames(species_jaccard_sim) %in% rownames(iso_vil)]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  
  temp <- data.frame(similarity = c(pop_vil_sim,
                                    mid_vil_sim,
                                    iso_vil_sim),
                     centrality = c(rep("Popular", length(pop_vil_sim)),
                                    rep("Middle", length(mid_vil_sim)),
                                    rep("Isolated", length(iso_vil_sim))),
                     village = rep(village_names[i],
                                   length(pop_vil_sim) + length(iso_vil_sim) + length(mid_vil_sim)))
  if(i == 1){
    pop_iso_sim_df <- temp
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, temp)
  }
  
  means_central <- aggregate(similarity ~  centrality, temp, median)
  
  p <- ggplot(temp, aes(x = centrality, y = similarity, fill = centrality)) +
    geom_boxplot() +
    #coord_cartesian(ylim = c(0,.2)) +
    stat_compare_means(label.y = .2) +
    ggtitle(village_names[i])+
    geom_text(data = means_central,
              aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                  y = similarity + 0.005))
  
  print(p)
  
}

means_central <- aggregate(similarity ~  centrality, pop_iso_sim_df, mean)

p <- ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  #coord_cartesian(ylim = c(0,.2)) +
  stat_compare_means(label.y = .2) +
  ggtitle("All Villages")+
  geom_text(data = means_central,
            aes(label = sprintf("%0.3f", round(similarity, digits = 3)),
                y = similarity + 0.005)) 
  
print(p)
#Opposite, isolated people are closer Woah

```


```{r}
species_jaccard_ssr <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(strain_rate), 
                                 colnames(species_jaccard_sim) %in% rownames(strain_rate)]

#These are really not correlated

species_jaccard_ssr_filt <- species_jaccard_ssr[1:50,1:50]
strain_rate_filt <- strain_rate[1:50,1:50]

plot(species_jaccard_ssr_filt, strain_rate_filt)
cor.test(species_bray_ssr_filt, strain_rate_filt)



#Ok Jaccard looks fucked, I'm just going to do it myself
species_bray_ssr <- species_bray[rownames(species_bray) %in% rownames(strain_rate), 
                                 colnames(species_bray) %in% rownames(strain_rate)]

species_bray_ssr <- species_bray_ssr[match(rownames(species_bray_ssr), rownames(strain_rate)),
                                     match(colnames(species_bray_ssr), rownames(strain_rate))]

species_bray_ssr_filt <- species_bray_ssr[1:50,1:50]
strain_rate_filt <- strain_rate[1:50,1:50]

#That's more what I expected
plot(species_bray_ssr_filt, species_jaccard_ssr_filt)
cor.test(species_bray_ssr_filt, species_jaccard_ssr_filt)


#Let's try NMDS here
for( i in 1:length(village_names)){
  my_nmds <- MASS::isoMDS(as.dist(1-species_jaccard_sim))
  
  # print the new coordinates for each city
  
  my_nmds <- as.data.frame(my_nmds$points)
  my_nmds$centrality <- centrality_df_quart$eigen_tri[match(rownames(my_nmds),
                                                            rownames(centrality_df_quart))]
  
  names(my_nmds) <- c("NMDS_1", "NMDS_2", "Centrality")
  
  my_nmds$Centrality <-as.factor(my_nmds$Centrality)
  my_nmds$centrality<- factor(my_nmds$centrality, levels=vils)
  
  
  p2 <- ggplot(my_nmds, aes(x = NMDS_1, y = NMDS_2, color = Centrality)) +
    geom_point() +
    ggtitle("NMDS of Strain-Sharing Rate") +
    scale_colour_manual(values = c("red", "blue", "darkgreen")) +
    stat_ellipse()
  
  p2
}

#that's wild
#Crazy, almost no correspondence


dim(species_bray_ssr)
dim(strain_rate)

library(ggpubr)
#Still lots of people with no sharing
ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,.2)) +
  stat_compare_means(label.y = .2)

#Central people much more similar, makes sense cool
wilcox.test(similarity ~ centrality, data = pop_iso_sim_df)


#Species Jaccard level

species_jaccard <- as.matrix(vegan::vegdist(species_data, method = "jaccard"),
                             nrow = nrow(species_data))



for(i in 1:length(village_names)){
  pop_vil <- centrality_df_quart_eigen %>% filter(village == village_names[i],
                                                  eigen_quart == "Popular")
  iso_vil <- centrality_df_quart_eigen %>% filter(village == village_names[i],
                                                  eigen_quart == "Isolated")
  
  pop_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(pop_vil),
                             colnames(species_jaccard_sim) %in% rownames(pop_vil)]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  iso_vil_sim <- species_jaccard_sim[rownames(species_jaccard_sim) %in% rownames(iso_vil),
                             colnames(species_jaccard_sim) %in% rownames(iso_vil)]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  if(i == 1){
    pop_iso_sim_df <- data.frame(similarity = c(pop_vil_sim,
                                                iso_vil_sim),
                                 centrality = c(rep("Popular", length(pop_vil_sim)),
                                                rep("Isolated", length(iso_vil_sim))),
                                 village = rep(village_names[i],
                                               length(pop_vil_sim) + length(iso_vil_sim)))
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, data.frame(similarity = c(pop_vil_sim,
                                                iso_vil_sim),
                                 centrality = c(rep("Popular", length(pop_vil_sim)),
                                                rep("Isolated", length(iso_vil_sim))),
                                 village = rep(village_names[i],
                                               length(pop_vil_sim) + length(iso_vil_sim))))
  }
  

}
#Id this returning jaccard similarity
#Still lots of people with no sharing
ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  #coord_cartesian(ylim = c(0,.2)) +
  stat_compare_means(label.y = .2)

#Central people much more similar, makes sense cool
wilcox.test(similarity ~ centrality, data = pop_iso_sim_df)


#Species Jaccard level

species_bray <- as.matrix(vegan::vegdist(species_data, method = "bray"),
                             nrow = nrow(species_data))



for(i in 1:length(village_names)){
  pop_vil <- centrality_df_quart_eigen %>% filter(village == village_names[i],
                                                  eigen_quart == "Popular")
  iso_vil <- centrality_df_quart_eigen %>% filter(village == village_names[i],
                                                  eigen_quart == "Isolated")
  
  pop_vil_sim <- species_bray[rownames(species_bray) %in% rownames(pop_vil),
                             colnames(species_bray) %in% rownames(pop_vil)]
  
  pop_vil_sim[lower.tri(pop_vil_sim, diag = TRUE)] <- NA
  
  pop_vil_sim <- na.omit(unlist(as.list(pop_vil_sim)))
  
  iso_vil_sim <- species_bray[rownames(species_bray) %in% rownames(iso_vil),
                             colnames(species_bray) %in% rownames(iso_vil)]
  
  iso_vil_sim[lower.tri(iso_vil_sim, diag = TRUE)] <- NA

  iso_vil_sim <- na.omit(unlist(as.list(iso_vil_sim)))
  
  if(i == 1){
    pop_iso_sim_df <- data.frame(similarity = c(pop_vil_sim,
                                                iso_vil_sim),
                                 centrality = c(rep("Popular", length(pop_vil_sim)),
                                                rep("Isolated", length(iso_vil_sim))),
                                 village = rep(village_names[i],
                                               length(pop_vil_sim) + length(iso_vil_sim)))
  }
  else{
    pop_iso_sim_df <- rbind(pop_iso_sim_df, data.frame(similarity = c(pop_vil_sim,
                                                iso_vil_sim),
                                 centrality = c(rep("Popular", length(pop_vil_sim)),
                                                rep("Isolated", length(iso_vil_sim))),
                                 village = rep(village_names[i],
                                               length(pop_vil_sim) + length(iso_vil_sim))))
  }
  

}
#Id this returning jaccard similarity
#Still lots of people with no sharing
ggplot(pop_iso_sim_df, aes(x = centrality, y = similarity, fill = centrality)) +
  geom_boxplot(outlier.shape = NA) +
  #coord_cartesian(ylim = c(0,.2)) +
  stat_compare_means(label.y = .2)

#Central people much more similar, makes sense cool
wilcox.test(similarity ~ centrality, data = pop_iso_sim_df)

#These things should be different, let's try anova again

```



Try out Aldex2

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("ALDEx2")

library(ALDEx2)
data(selex)
#subset only the last 400 features for efficiency
selex.sub <- selex[1:400,]
selex.sub[1:5,1:5]
species_data_filt[1:5,1:5]
species_data_filt <- t(species_data_filt)

conds <- c(rep("NS", 7), rep("S", 7))

#Make network into quartiles

centrality_df_quart <- centrality_df %>%
  group_by(village) %>%
  mutate(eigen_tri = case_when(
    eigen_c >= quantile(eigen_c, .66) ~ "Popular",
    eigen_c <= quantile(eigen_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  between_tri = case_when(
    between_c >= quantile(between_c, .66) ~ "Popular",
    between_c <= quantile(between_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  ),
  degree_tri = case_when(
    degree_c >= quantile(degree_c, .66) ~ "Popular",
    degree_c <= quantile(degree_c, .33) ~ "Isolated",
    TRUE ~ "Middle"
  )) %>%
  ungroup() %>%as.data.frame()

rownames(centrality_df_quart) <- rownames(centrality_df)

centrality_df_quart_eigen <- centrality_df_quart %>% filter(eigen_quart == "Popular" |
                                                        eigen_quart == "Isolated")

centrality_df_quart_degree <- centrality_df_quart %>% filter(degree_quart == "Popular" |
                                                        degree_quart == "Isolated")

centrality_df_quart_between <- centrality_df_quart %>% filter(between_quart == "Popular" |
                                                        between_quart == "Isolated")


species_data_filt_eigen <- species_data_filt
species_data_filt_between <- species_data_filt
species_data_filt_degree <- species_data_filt

species_data_filt_eigen <- species_data_filt_eigen[,colnames(species_data_filt_eigen) %in% rownames(centrality_df_quart_eigen)]

species_data_filt_between <- species_data_filt_between[,colnames(species_data_filt_between) %in% rownames(centrality_df_quart_between)]

species_data_filt_degree <- species_data_filt_degree[,colnames(species_data_filt_degree) %in% rownames(centrality_df_quart_degree)]

#Order to same row
centrality_df_quart_degree <- centrality_df_quart_degree[match(colnames(species_data_filt_degree),
                                                 rownames(centrality_df_quart_degree)),]

centrality_df_quart_between <- centrality_df_quart_between[match(colnames(species_data_filt_between),
                                                 rownames(centrality_df_quart_between)),]

centrality_df_quart_eigen <- centrality_df_quart_eigen[match(colnames(species_data_filt_eigen),
                                                 rownames(centrality_df_quart_eigen)),]


#Remove rows with no values
to_remove <- rowMeans(species_data_filt_eigen) ==0
species_data_filt_eigen <- species_data_filt_eigen[!to_remove,]

to_remove <- rowMeans(species_data_filt_degree) ==0
species_data_filt_degree <- species_data_filt_degree[!to_remove,]

to_remove <- rowMeans(species_data_filt_between) ==0
species_data_filt_between <- species_data_filt_between[!to_remove,]

#Check the same order
rownames(centrality_df_quart_eigen) == colnames(species_data_filt_eigen)
rownames(centrality_df_quart_between) == colnames(species_data_filt_between)
rownames(centrality_df_quart_degree) == colnames(species_data_filt_degree)


species_data_filt_eigen <- compositions::clr(species_data_filt_eigen)
species_data_filt_degree <- compositions::clr(species_data_filt_degree)
species_data_filt_between <- compositions::clr(species_data_filt_between)


wilcoxon_p_eigen <- c() # Initialize empty vector for p-values
for(i in 1:nrow(species_data_filt_eigen)){
  result <- wilcox.test(species_data_filt_eigen[i,] ~ centrality_df_quart_eigen$eigen_quart)
  wilcoxon_p_eigen[[i]]  <- result$p.value
}

wilcoxon_p_degree <- c()
for(i in 1:nrow(species_data_filt_degree)){
  result <- wilcox.test(species_data_filt_degree[i,] ~ centrality_df_quart_degree$degree_quart)
  wilcoxon_p_degree[[i]]  <- result$p.value
}

wilcoxon_p_between <- c()
for(i in 1:nrow(species_data_filt_between)){
  result <- wilcox.test(species_data_filt_between[i,] ~ centrality_df_quart_between$between_quart)
  wilcoxon_p_between[[i]]  <- result$p.value
}

wilcoxon_p_between <- data.frame(taxa =  rownames(species_data_filt_between),
                         p_raw = unlist(wilcoxon_p_between))

wilcoxon_p_between$p_adjusted <- p.adjust(wilcoxon_p_between$p_raw, method = "fdr")

wilcoxon_p_between %>% arrange(p_adjusted) %>% head()

wilcoxon_p_degree <- data.frame(taxa =  rownames(species_data_filt_degree),
                         p_raw = unlist(wilcoxon_p_degree))

wilcoxon_p_degree$p_adjusted <- p.adjust(wilcoxon_p_degree$p_raw, method = "fdr")


wilcoxon_p_degree %>% arrange(p_adjusted) %>% head()


wilcoxon_p_eigen <- data.frame(taxa =  rownames(species_data_filt_eigen),
                         p_raw = unlist(wilcoxon_p_eigen))

wilcoxon_p_eigen$p_adjusted <- p.adjust(wilcoxon_p_eigen$p_raw, method = "fdr")

wilcoxon_p_eigen %>% arrange(p_adjusted) %>% head()
#Eigen doesn't even hold up, probably was spurious, could try trichotomizing, seems like that's what he like, have higher 
#{f__Prevotellaceae}GGB1239_SGB1657 (SGB1657) chosen by both eigen and degree
#Low value for between
#Maybe just do the 100 most prevalent to cut down on adjustment

plot(centrality_df_quart_eigen$eigen_c,species_data_filt_eigen[rownames(species_data_filt_eigen) == '{f__Prevotellaceae}GGB1239_SGB1657 (SGB1657)',])

mean(species_data_filt_eigen[rownames(species_data_filt_eigen) == '{f__Prevotellaceae}GGB1239_SGB1657 (SGB1657)',
                             centrality_df_quart_eigen$eigen_quart == "Popular"])

mean(species_data_filt_eigen[rownames(species_data_filt_eigen) == '{f__Prevotellaceae}GGB1239_SGB1657 (SGB1657)',
                             centrality_df_quart_eigen$eigen_quart == "Isolated"])

#That looks fairly legit
#Maybe just use aldex once we get the counts data

rowSums(species_data_filt_eigen)
wilcoxon_p_eigen %>% arrange(p_adjusted) %>% head()
#HMM maybe try clr
x <-compositions::clr(species_data_filt_eigen)
x[1:5,1:5]
#Columsn can be whatever, I'm chilling
colSums(x)
cor.test()
dim(wilcoxon_p_between)


for(i in 1:nrow(species_data_filt_eigen)){
  result <- wilcox.test(species_data_filt_eigen[i,] ~ centrality_df_quart_eigen$eigen_quart)
  wilcoxon_p_eigen[[i]]  <- result$p.value
  
  result <- wilcox.test(species_data_filt_degree[i,] ~ centrality_df_quart_degree$degree_quart)
  wilcoxon_p_degree[[i]]  <- result$p.value
  
  result <- wilcox.test(species_data_filt_between[i,] ~ centrality_df_quart_between$between_quart)
  wilcoxon_p_between[[i]]  <- result$p.value
}

length(unlist(wilcoxon_p))

wilcoxon_p <- data.frame(taxa =  rownames(species_data_filt_eigen),
                         p_raw = unlist(wilcoxon_p))

wilcoxon_p$p_adjusted <- p.adjust(wilcoxon_p$p_raw, method = "fdr")


df <- data.frame(x = c(wilcoxon_p$p_raw, wilcoxon_p$p_adjusted), 
                type=rep(c("raw", "fdr"),
        c(length(wilcoxon_p$p_raw),
          length(wilcoxon_p$p_adjusted))))

# make a histrogram of p values and adjusted p values
wilcoxon_plot <- ggplot(df) +
  geom_histogram(aes(x=x, fill=type)) +
  labs(x = "p-value", y = "Frequency") 

wilcoxon_plot

#Only one, damn, maybe the others will
#Also try CLR

wilcoxon_p %>% arrange(p_adjusted)


plot(centrality_df_quart$eigen_c,species_data_filt_eigen[rownames(species_data_filt_eigen) == 'Alistipes_senegalensis (SGB2296)',])

mean(species_data_filt_eigen[rownames(species_data_filt_eigen) == 'Alistipes_senegalensis (SGB2296)',
                             centrality_df_quart$eigen_quart == "Popular"])

mean(species_data_filt_eigen[rownames(species_data_filt_eigen) == 'Alistipes_senegalensis (SGB2296)',
                             centrality_df_quart$eigen_quart == "Isolated"])

#This could be becaus of the difference in villages though, do I want to pull the same number from each village? 

#Much lower, intersting, ok I'm down to do this, how to make sure it's
#Doesn't correlate


#Could stratify by villages

```


```{r}
x.all <- aldex(selex.sub, conds, mc.samples=16, test="t", effect=TRUE,
     include.sample.summary=FALSE, denom="all", verbose=FALSE, paired.test=FALSE)

par(mfrow=c(1,1))
aldex.plot(x.all, type="MA", test="welch", xlab="Log-ratio abundance",
    ylab="Difference")
aldex.plot(x.all, type="MW", test="welch", xlab="Dispersion",
    ylab="Difference")

# the output is in the S3 object 'x'
?aldex.clr
x <- aldex.clr(species_data_filt_eigen, centrality_df_quart$eigen_quart, mc.samples=16, denom="all", verbose=F)
str(x)

x.tt <- aldex.ttest(x, paired.test=FALSE, verbose=FALSE)

x.kw <- aldex.kw(x)
?aldex.effect
x.effect <- aldex.effect(x, CI=T, verbose=FALSE)#, paired.test=FALSE)

x.all <- data.frame(x.tt,x.effect)

par(mfrow=c(1,2))
aldex.plot(x.all, type="MA", test="welch")
aldex.plot(x.all, type="MW", test="welch")
#Putting relative abundance in here will fuck up, damn it
```




Probably easier to do pairwise, if there's a significant correlation keep the species name
I can filter to those later
```{r}
#Get clr composition
library(compositions)

species_data_binary <- species_data
species_data_binary[species_data_binary >0] <- 1

species_data_clr <- clr(species_data)

species_data_clr <- species_data_clr[rownames(species_data_clr) %in% centrality_df$respondent_master_id]
species_data_clr <- species_data_clr[,colSums(species_data_clr) != 0]

species_data_binary <- species_data_binary[,rownames(species_data_binary) %in%
                                             centrality_df$respondent_master_id]

species_data_binary <- species_data_binary[,colSums(species_data_binary) >= 30]
species_data_binary <- data.frame(species_data_binary)
species_data_binary$respondent_master_id <- rownames(species_data_binary)

species_data_binary <- merge(species_data_binary, centrality_sim_df_covars_all)

#Should scale my variables
species_data_binary$eigen_c <- (species_data_binary$eigen_c - mean(species_data_binary$eigen_c))/sd(species_data_binary$eigen_c)

species_data_binary$degree_c <- (species_data_binary$degree_c - mean(species_data_binary$degree_c))/sd(species_data_binary$degree_c)

species_data_binary$between_c <- (species_data_binary$between_c - mean(species_data_binary$between_c))/sd(species_data_binary$between_c)

species_data_binary <- species_data_binary[, colnames(species_data_binary) != "respondent_master_id"]

# head(centrality_sim_df_covars)
# dim(species_data_binary)
# species_data_binary <- data.frame(species_data_binary)
# species_data_binary[1:5,1:5]
# str(species_data_binary)
# 
# dim(centrality_sim_df_covars)
# centrality_sim_df_covars
# 
# species_data_binary <- cbind(species_data_binary,
#                           centrality_df$eigen_c[match(rownames(species_data_binary),
#                                                       centrality_df$respondent_master_id)])
# 
# colnames(species_data_binary)[1127] <- "Eigen"
# 
# species_data_binary <- cbind(species_data_binary,
#                           centrality_df$degree_c[match(rownames(species_data_binary),
#                                                       centrality_df$respondent_master_id)])
# 
# colnames(species_data_binary)[1128] <- "Degree"
# 
# species_data_binary <- cbind(species_data_binary,
#                           centrality_df$between_c[match(rownames(species_data_binary),
#                                                       centrality_df$respondent_master_id)])
# 
# colnames(species_data_binary)[1129] <- "Between"
# 
# species_data_binary <- cbind(species_data_binary,
#                           centrality_df$village[match(rownames(species_data_binary),
#                                                       centrality_df$respondent_master_id)])
# 
# colnames(species_data_binary)[1130] <- "Village"

for(i in 1:length(village_names)){
  sn_vil <- SN %>% filter(village_name_w3 == village_names[i])
  village_ids <- unique(c(sn_vil$ego, sn_vil$alter))
  sn_vil <- simplify(graph_from_data_frame(sn_vil, directed = FALSE))
  crossclique_vil <- centiserve::crossclique(sn_vil)
  #strain_vil <- strain_rate[rownames(strain_rate) %in% village_ids,
  #                          colnames(strain_rate) %in% village_ids]
  #diag(strain_vil) <- NA
  #strain_sim <- colMeans(strain_vil,na.rm = TRUE)
  eigen_vil <- eigen_centrality(sn_vil)$vector
  between_vil <- igraph::betweenness(sn_vil, normalized = TRUE)
  degree_vil <- igraph::degree(sn_vil)
  #strain_sim <- strain_sim[match(names(eigen_vil), names(strain_sim))]
  if(i == 1){
    centrality_df <- data.frame(respondent_master_id = names(V(sn_vil)),
                                crossclique_c = unname(crossclique_vil),
                                eigen_c = unname(eigen_vil),
                                between_c = unname(between_vil),
                                degree_c = unname(degree_vil),
                                village = rep(village_names[i], length(crossclique_vil)),
                                strain_sim_all = unname(strain_sim)
                                )
  }
  else{
    centrality_df <- rbind(centrality_df,
                                       data.frame(respondent_master_id = names(V(sn_vil)),
                                                  crossclique_c = unname(crossclique_vil),
                                                  eigen_c = unname(eigen_vil),
                                                  between_c = unname(between_vil),
                                                  degree_c = unname(degree_vil),
                                                  village = rep(village_names[i],
                                                                length(crossclique_vil)),
                                                   strain_sim_all = unname(strain_sim)
                                       ))
  }
}

dim(species_data_binary)
dim(centrality_sim_df_covars_all)
1146-20

dim(og_pval_df)
#Maybe better to just do is it present and then see
p_vals <- c()

new_frame <- species_data_binary
new_frame <- data.frame(new_frame)

betas_between <- c()
betas_eigen <- c()
betas_degree <- c()

p_vals_between <- c()
p_vals_eigen <- c()
p_vals_degree <- c()


for(i in 1:1126){
  colnames(new_frame)[i] <- "species"
  
  test_between <- lme4::glmer(species ~ between_c +
                                age_at_survey +
                                gender +
                                household_wealth_index_w3 +
                                BMI +
                                dna_conc +
                           (1|village_name),
                      data = new_frame,
                      family = binomial)
  
  test_eigen <- lme4::glmer(species ~ eigen_c +
                                age_at_survey +
                                gender +
                                household_wealth_index_w3 +
                                BMI +
                                dna_conc +
                           (1|village_name),
                      data = new_frame,
                      family = binomial)
  
  test_degree <- lme4::glmer(species ~ degree_c +
                                age_at_survey +
                                gender +
                                household_wealth_index_w3 +
                                BMI +
                                dna_conc +
                           (1|village_name),
                      data = new_frame,
                      family = binomial)
  
  
  p_vals_between <- c(p_vals_between, car::Anova(test_between)["between_c", "Pr(>Chisq)"])
  p_vals_eigen <- c(p_vals_eigen, car::Anova(test_eigen)["eigen_c", "Pr(>Chisq)"])
  p_vals_degree <- c(p_vals_degree, car::Anova(test_degree)["degree_c", "Pr(>Chisq)"])
  
  betas_between <- c(betas_between, test_between@beta[2])
  betas_eigen <- c(betas_eigen, test_eigen@beta[2])
  betas_degree <- c(betas_degree, test_degree@beta[2])
  
  colnames(new_frame)[i] <- "done"
  
  print(i)

}

#add in controls next
#Looks like we'll pick up a lot of niche spices, let's try to find central ones will be interesting

#Probably want to check for correlations between villages
#Hopefully of the bacteria that are in common they both have similar effect sizes and directions

#For the warnings, maybe don't do a mixed effect, or redo it at the village level and see how well results line up
og_pval_df <- data.frame(p_vals_between, p_vals_eigen, p_vals_degree)
og_beta_df <- data.frame(betas_between, betas_eigen, betas_degree)

cor.test(betas_between, betas_degree)

#Suggest there's some legit ones
p_vals_adj <- p.adjust(c(p_vals_degree,p_vals_between,p_vals_eigen), method = "BH")

p_vals_degree_adj <- p_vals_adj[1:50]
p_vals_between_adj <- p_vals_adj[51:100]
p_vals_eigen_adj <- p_vals_adj[101:150]

p_vals_degree_adj <- p_vals_adj[1:1126]
p_vals_between_adj <- p_vals_adj[1127:2252]
p_vals_eigen_adj <- p_vals_adj[2253:3378]

adj_pval_df <- data.frame(p_vals_between_adj, p_vals_eigen_adj, p_vals_degree_adj)

hist(p_vals_adj)

to_keep <- p_vals_between_adj <.05 |  p_vals_degree_adj <.05 |  p_vals_eigen_adj <.05

sum(to_keep)

adj_pval_df_filter <- adj_pval_df[to_keep,]
og_beta_df_filter <- og_beta_df[to_keep,]

rownames(og_beta_df_filter) <- colnames(species_data_binary)[to_keep]
colnames(og_beta_df_filter) <- c("Betweenness Centrality","Eigenvector Centrality", "Degree Centrality")

og_beta_df_filter <- as.matrix(og_beta_df_filter)
adj_pval_df_filter <- as.matrix(adj_pval_df_filter)
str(adj_pval_df_filter)
str(og_beta_df_filter)
?gsub
rownames(og_beta_df_filter) <- gsub(" \\(SGB(.*)", "", rownames(og_beta_df_filter))

#Take the 20 most significant Double check this, I'm surprised there are so many positive
#Probably with dovariates these will decrease

plot(as.numeric(new_frame[,305]) ~ as.numeric(new_frame[,colnames(new_frame) == "Between"]))

min(og_beta_df_filter)
corrplot(og_beta_df_filter,
         p.mat = adj_pval_df_filter,
         sig.level = 0.05,
         is.corr = FALSE,
         tl.cex = .75,
         cl.pos = 'b',
         col.lim = c(-.5,.5))


corrplot(as.matrix(og_beta_df), p.mat = as.matrix(adj_pval_df), sig.level = 0.05)

to_keep <- (betas_between>0 & p_vals_between_adj < .05) |
  (betas_between>0 & p_vals_between_adj < .05)
(betas_between>0 & p_vals_between_adj < .05)


sum(betas_between>0 & p_vals_between_adj < .05)

corrplot(as.matrix(og_beta_df), p.mat = as.matrix(adj_pval_df), sig.level = 0.05)

plot(p_vals_degree,p_vals_between)

hist(p_vals_adj)
#Want to control for covariates as well
#Maybe

library(corrplot)
testRes = cor.mtest(mtcars, conf.level = 0.95)
M = cor(mtcars)
str(M)
str(testRes$p)
#Make it a numeric matrix with named dims, easy

corrplot(as.matrix(M), p.mat = as.matrix(adj_pval_df), sig.level = 0.05)
#, order = 'hclust', addrect = 2



plot(as.numeric(new_frame[,305]) ~ as.numeric(new_frame[,colnames(new_frame) == "Between"]))

which(p_vals_adj <= .05)

head(sort(p_vals_adj))
plot(as.numeric(new_frame[,185]) ~as.numeric(new_frame[,colnames(new_frame) == "Between"]))


plot(as.numeric(species_data_clr[,23]) ~
                           as.numeric(species_data_clr[,colnames(species_data_clr) == "Between"]))

colnames(species_data)[23]


p <- pheatmap(plotDFValues,annotation_row = NULL,annotation_names_row = T,labels_row = rownames(plotDFValues),legend = T,
                show_rownames = T, cluster_rows = clusterFeatures,cluster_cols = clusterPhenos,angle_col = 90,
                fontsize_number = textSize,border_color = "#EEEEEE",na_col = "white",fontsize = legendTextSize,
                treeheight_row = 0, treeheight_col = 0,legend_labels = "sig*log(p-value)",color = myColor,
                fontsize_col = colTextSize,fontsize_row = rowTextSize,display_numbers = plotDFText,breaks = myBreaks,
                cellwidth = cellWidth,cellheight = cellHeight,filename = NA)
install.packages('pheatmap')
library(pheatmap)

example_file <- "https://davetang.org/file/TagSeqExample.tab"

trial_data <- read.delim(example_file, header=T, row.names="gene")

M = cor(mtcars)
str(M)
corrplot(M, p.mat = testRes$p, sig.level = 0.10, order = 'hclust', addrect = 2)

```







```{r}
# =================================================================
# heatmap plotter for DAG3 phenotype-feature associations (V2)
# =================================================================
# Notes:
#   V1 uses (now obsolete) BEZI models, this one uses new batch of Alex's results
# Parameters:
# 
#  phenosToPlot : which phenotypes to plot (must match phenotype column names, no default)
#  inData* : loaded dataframe with associations (produced by Alex)
#  statToPlot [def=pval]: what to plot, other options: coef, qval
#  featuresToPlot [def=G]: which features to consider, options: "Taxa" for all taxa, "S","G","F","O","P","K" for appropriate levels
#  clusterPhenos [def=T]: if True, clusters phenotypes
#  sigStat [def=pval]: which stat to consider for singificance, options: qval
#  sigStatNominal [def=pval]: which stat to consider for nominal significance, options: qval
#  sigValue [def=0.05]: significance cutoff for sigStat
#  sigNominal [def=0.05]: significance cutoff for sigStatNominal
#  addText [def=Direction]: other options: "","Significance"
#  plotValuesSig [def=all]: what to plot & color: all (no significance filter), nomSig (nominal signifiance < sigNominal) or padjSig (padj significance < sigValue)
#  plotTextSig [def=all]:   what to put text on: all (no significance filter), nomSig (nominal signifiance < sigNominal) or padjSig (padj significance < sigValue) 
#  transformValues [def=T]: if T, does -1*log transform on p-values [qval, pval], no transformation on effect
#  logLimit [def=10]: limit log-values to entered number
#  nonLogLimit [def = NA] : limit non-log-values to entered number
plotAssociationsDag3HeatmapV2 <- function(phenosToPlot,
                                          inData,
                                          nrFeaturesToPlot = 20,
                                          featuresToPlot = "G",
                                          dataType = "taxon",
                                          clusterPhenos = T,
                                          clusterFeatures = T,
                                          sigStat = "PadjBH",
                                          sigStatNominal = "Pvalue",
                                          sigValue = 0.05, 
                                          sigNominal = 0.05, 
                                          statToPlot = "Pvalue", 
                                          addText = "Direction",
                                          plotValuesSig = "nomSig",
                                          plotTextSig = "padjSig", 
                                          transformValues=T,
                                          logLimit = 10.0,
                                          nonLogLimit = NA,
                                          sigAll = 0.9, 
                                          textSize=15, 
                                          colLow = "Orange", 
                                          colHigh = "Darkblue",
                                          colTextSize = 12,
                                          rowTextSize = 12,
                                          legendTextSize = 10,
                                          cellWidth=15, 
                                          cellHeight=15,
                                          nrColors = 13,
                                          flipCoords = T,
                                          doRefactor=F,
                                          sortPhenos = F,
                                          refactorIncludeAllClasses=F,
                                          trimNames = F,
                                          retData=F,
                                          keepOrder=F,
                                          directionValue = "effect.size"
)

{
  phenoOrder = phenosToPlot
  # other variables
  featuresToPlotGrep = ""
  # ================================================
  # ERROR CHECK:
  # =================================================
  print ('>> Function plotTaxaAssociationsHeatmap (V2) started ...')
  if (!sigStat %in% c("Pvalue",	"PadjBH","PadjBonferroni") ) {
    stop("ERROR: sigStat parameter MUST BE one of [Pvalue, PadjBH, PadjBonferroni]")
  }
  if (!statToPlot %in% c("Pvalue",	"PadjBH","PadjBonferroni","F.stat","R2","effect.size","z.score") ) {
    stop("ERROR: statToPlot parameter MUST BE one of [Pvalue, PadjBH, PadjBonferroni, R2, F.stat, effect.size, z.score]")
  }
  if (!addText %in% c("","Direction","Significance")) {
    stop(paste0("ERROR: addText parameter MUST BE one of ['Direction', 'Significance', '']"))
  }
  if (!plotValuesSig %in% c("all","nomSig","padjSig")) {
    stop(paste0("ERROR: plotValuesSig parameter MUST BE one of ['all', 'nomSig', 'padjSig']"))
  }
  if (!plotTextSig %in% c("all","nomSig","padjSig")) {
    stop(paste0("ERROR: plotTextSig parameter MUST BE one of ['all', 'nomSig', 'padjSig']"))
  }
  if (!dataType %in% c("taxon","pathway")) {
    stop(paste0("ERROR: dataType parameter MUST BE one of ['taxon', 'pathway']"))
  }
  
  if (featuresToPlot == "All") {
    featuresToPlotGrep = "*"
  } else if (featuresToPlot == "Taxa") {
    featuresToPlotGrep = "[sgfopk]__"
  } else if (featuresToPlot == "S") {
    featuresToPlotGrep = "s__"
  } else if (featuresToPlot == "G") {
    featuresToPlotGrep = "g__"
  } else if (featuresToPlot == "F") {
    featuresToPlotGrep = "f__"
  } else if (featuresToPlot == "O") {
    featuresToPlotGrep = "o__"
  } else if (featuresToPlot == "P") {
    featuresToPlotGrep = 'p__'
  } else if (featuresToPlot == "K") {
    featuresToPlotGrep = 'k__'
  } else {
    stop(paste0("ERROR: featuresToPlot MUST BE one of [Taxa | All, S, G, F, O, P, K]"))
  }
  # ================================================
  
  # load data
  # ===========================
  print ('> loading data')
  inDF <- inData
  # test for missing phenotypes
  if (sum(inDF$phenotype %in% phenosToPlot) == 0) {
    stop(paste0("ERROR: no phenotypes could be found, check phenosToPlot & dataPath parameters!"))
  }
  # fix column names
  inDFf <- inDF[inDF$phenotype %in% phenosToPlot,]
  #colnames(inDFf) <- gsub('\\.full$','\\.FullModel',colnames(inDFf))
  toPlotValue = statToPlot
  # calculate z.score if requested to plot
  if (toPlotValue == 'z.score') {
    inDFf$z.score = -qnorm(inDFf$Pvalue/2)
  }
  nominalSigParameter = sigStatNominal
  sigParameter = sigStat
  
  # test for non-existing models (statistic to plot)
  if (!toPlotValue %in% colnames(inDFf)) {
    stop(paste0('ERROR: stat "',statToPlot,' does not exist in data, try different statToPlot!'))
  }
  # test for non-existing models (nominal significance)
  if (!nominalSigParameter %in% colnames(inDFf)) {
    stop(paste0('ERROR: stat "',nominalSigParameter,' does not exist in data, try different nominalSigParameter!'))
  }
  # test for non-existing direction values
  if (!directionValue %in% colnames(inDFf)) {
    stop(paste0('ERROR: directionStat "',directionValue,' does not exist in data, try directionStat = R2'))
  }
  # test for non-existing direction values
  if (!sigParameter %in% colnames(inDFf)) {
    stop(paste0('ERROR: sigStat "',sigParameter,'" does not exist in data, try different sigStat!'))
  }
  

  # ================================================================
  # > refactor: keep 2nd and other factors, make new variables for each of there
  # NOTE: we only do this if we plot direction!
  # otherwise direction is average of all directions!
  # ================================================================
  if (doRefactor) {
    print ('reshaping factor results to long table')
    # refactor factor variables into multiple variables
    # > find factors
    phenosUnique <- unique(inDFf$phenotype)
    phenosFac <- c()
    for (ph in phenosUnique) {
      tt <- inDFf$levels[inDFf$phenotype == ph][1]
      #print(tt)
      if (grepl('\\:', tt)) {
        phenosFac <- c(phenosFac,ph)
      }
    }
    #inDFfbak <- inDFf
    print ('reshaping factor results to long table')
    cntr = 0
    newDFlist <- list() # accumulate in list for speed
    for (ph in phenosFac) {
      phDF <- inDFf[inDFf$phenotype==ph,]
      inDFf <- inDFf[inDFf$phenotype!=ph,]
      phLvls <- phDF$levels[phDF$phenotype == ph][1]
      print(paste0(' > refactoring ',ph,' <levels: ',phLvls,'>'))
      for (cc in c(1:nrow(phDF))) {
        oneRow <- phDF[cc,]
        splitLvls <- unlist(strsplit(oneRow$levels,':')) # levels split
        splitSS <- unlist(strsplit(oneRow$levels_SampleSize,':'))   # sample size split
        splitES <- unlist(strsplit(oneRow$effect.size,':'))  # effect size split
        if (refactorIncludeAllClasses) {startC = 1} else {startC = 2}
        if (dataType=="taxon") {dataTyp="taxon"
        } else if (dataType=="pathway") {dataTyp="pathway"}
        for (ln in c(startC:length(splitLvls))) {
          newRow <- data.frame(phenotype=paste0(oneRow$phenotype,'.C',ln-1,'_',splitLvls[ln]),
                               taxon=oneRow[[dataTyp]],
                               Nsamples=oneRow$Nsamples,
                               levels=splitLvls[ln],
                               levels_SampleSize=splitSS[ln],
                               effect.size=splitES[ln],
                               effect.size.asInteger=oneRow$effect.size.asInteger,
                               R2=oneRow$R2,
                               F.stat=oneRow$F.stat,
                               Pvalue=oneRow$Pvalue,
                               PadjBH=oneRow$PadjBH,
                               PadjBonferroni=oneRow$PadjBonferroni)
          cntr <- cntr+1
          newDFlist[[cntr]] <- newRow
        }
      }
    }
    print ('  > making dataframe')
    newDF <- do.call(rbind.data.frame, newDFlist)
    print ('  > sorting dataframe')
    newDF <- newDF[order(newDF$phenotype),]
    # band-aid
    if ("FDR" %in% colnames(inDFf) & !("FDR" %in% colnames(newDF))) {
      newDF$FDR <- newDF$PadjBH
    }
    print ('  > merging with original')
    if (dataType=="taxon") {colnames(newDF)[2] <- "taxon"
    } else if (dataType=="pathway") {colnames(newDF)[2] <- "pathway"}
    
    inDFf <- rbind.data.frame(inDFf,newDF)
    print ('reshaping done!')
  } else {
    # average directions: if 2 classes, take 2nd, if > 3 classes, take average
    for (cc in c(1:nrow(inDFf))) {
      oneRow <- inDFf[cc,]
      if (grepl('\\:',oneRow$effect.size)) {
        splitLvls <- unlist(strsplit(oneRow$levels,':')) # levels split
        #splitSS <- unlist(strsplit(oneRow$levels_SampleSize,':'))   # sample size split
        splitES <- unlist(strsplit(oneRow$effect.size,':'))  # effect size split
        if (length(splitLvls==2)) {
          oneRow$effect.size <- splitES[2]
          inDFf[cc,] <- oneRow
        } else {
          oneRow$effect.size <- oneRow$effect.size.asInteger
          inDFf[cc,] <- oneRow
        }
      }
    }
  }
  
  # collect data from results file
  if (!(dataType %in% colnames(inDFf))) {
    stop(paste0(' ERROR: ',dataType,' column not in input data, note: double-check the input data!'))
  }
  inDFfs <- inDFf[,c("phenotype",dataType,statToPlot,sigParameter,nominalSigParameter,directionValue)]
  # collect only values within nominal significance (as defined by parameters)
  inDFfs <- inDFfs[inDFfs[[nominalSigParameter]] < sigAll,]
  inDFfs <- inDFfs[complete.cases(inDFfs),]
  colnames(inDFfs) <- c("Phenotype","Feature","ValueToPlot","Significance","NominalSig","Direction")
  if (nrow(inDFfs) == 0) {
    stop('WARNING: No significant results found, stopping!')
  }
  # shorten names
  if (dataType=="taxon") {
    inDFfs$Feature <- as.character(inDFfs$Feature)
    for (r in c(1:nrow(inDFfs))) {
      #print(inDFfs$Taxon[r])
      inDFfs$Feature[r] <- (purgeMGNameOne(inDFfs$Feature[r]))
    }
  }
  
  # make wide dataframe for heatmap plotting
  # ======================================
  inDFwide <- reshape(inDFfs, idvar = "Phenotype", timevar = "Feature", direction = "wide")
  # kill class bug
  for (cc in colnames(inDFwide)) {
    inDFwide[[cc]] <- as.character(inDFwide[[cc]])
  }
  
  # subset taxa
  rownames(inDFwide) <- inDFwide$Phenotype
  inDFwide <- inDFwide[,grep(featuresToPlotGrep,colnames(inDFwide))]
  if ("Phenotype" %in% colnames(inDFwide)) {
    inDFwide$Phenotype <- NULL
  }
  
  # extract individual dataframes
  # >>> DIRECTION DF
  inDirWide <- inDFwide[,c(grep('^Phenotype',colnames(inDFwide)),grep('^Direction',colnames(inDFwide)))]
  colnames(inDirWide) <- gsub('Direction\\.','',colnames(inDirWide))
  #  NAs for direction: values are 0 for purposes of plotting (no direction)
  for (cn in colnames(inDirWide)[colnames(inDirWide)!="Phenotype"] ) {
    inDirWide[[cn]] <- as.character(inDirWide[[cn]])
    inDirWide[[cn]][is.na(inDirWide[[cn]])] <- "0.0"
    inDirWide[[cn]] <- as.numeric(inDirWide[[cn]])
    inDirWide[[cn]] <- sign(as.numeric(inDirWide[[cn]]))
  }
  # rownames(inDirWide) <- inDirWide$Phenotype
  # inDirWide$Phenotype <- NULL
  
  # >>> VALUE DF
  inValueWide <- inDFwide[,c(grep('^Phenotype',colnames(inDFwide)),grep('^ValueToPlot',colnames(inDFwide)))]
  colnames(inValueWide) <- gsub('ValueToPlot\\.','',colnames(inValueWide))
  #  NAs for values:
  #  if using p-values: values are 1 for purposes of plotting (p-value 1)
  #  otherwise values are 0 for purposes of plotting (effect size, chi-squared statistic, correlation)
  if (statToPlot %in% c("Pvalue",	"PadjBH","PadjBonferroni")) {
    for (cn in colnames(inValueWide)[colnames(inValueWide)!="Phenotype"]) {
      inValueWide[[cn]] <- as.numeric(inValueWide[[cn]])
      inValueWide[[cn]][is.na(inValueWide[[cn]])] <- 1.0
    }
  } else {
    for (cn in colnames(inValueWide)[colnames(inValueWide)!="Phenotype"]) {
      inValueWide[[cn]] <- as.numeric(inValueWide[[cn]])
      inValueWide[[cn]][is.na(inValueWide[[cn]])] <- 0.0
    }
  }
  # rownames(inValueWide) <- inValueWide$Phenotype
  # inValueWide$Phenotype <- NULL
  
  # >>> SIGNIFICANCE DATAFRAME (adjusted SIG)
  inSigAdjWide <- inDFwide[,c(grep('^Phenotype',colnames(inDFwide)),grep('^Significance',colnames(inDFwide)))]
  colnames(inSigAdjWide) <- gsub('Significance\\.','',colnames(inSigAdjWide))
  #  NAs for values:
  #  if using p-values: values are 1 for purposes of plotting (p-value 1)
  #  otherwise values are 0 for purposes of plotting (effect size, chi-squared statistic, correlation)
  for (cn in colnames(inSigAdjWide)[colnames(inSigAdjWide)!="Phenotype"]) {
    inSigAdjWide[[cn]][is.na(inSigAdjWide[[cn]])] <- 1.0
    inSigAdjWide[[cn]] <- as.numeric(as.character(inSigAdjWide[[cn]]))
  }
  # rownames(inSigAdjWide) <- inSigAdjWide$Phenotype
  # inSigAdjWide$Phenotype <- NULL
  
  # >>> NOMINAL SIGNIFICANCE DATAFRAME (SIG)
  inSigNomWide <- inDFwide[,c(grep('^Phenotype',colnames(inDFwide)),grep('^NominalSig',colnames(inDFwide)))]
  colnames(inSigNomWide) <- gsub('NominalSig\\.','',colnames(inSigNomWide))
  #  NAs for values:
  #  if using p-values: values are 1 for purposes of plotting (p-value 1)
  #  otherwise values are 0 for purposes of plotting (effect size, chi-squared statistic, correlation)
  for (cn in colnames(inSigNomWide)[colnames(inSigNomWide)!="Phenotype"]) {
    inSigNomWide[[cn]][is.na(inSigNomWide[[cn]])] <- 1.0
    inSigNomWide[[cn]] <- as.numeric(as.character(inSigNomWide[[cn]]))
  }
  # rownames(inSigNomWide) <- inSigNomWide$Phenotype
  # inSigNomWide$Phenotype <- NULL
  
  # >>> PREP TEXT DATAFRAME (with +/- for direction or * for significance)
  doAddText = F
  if (addText == "Direction") {
    doAddText = T
    inTextWide <- as.data.frame(inDirWide)
    for (cn in colnames(inTextWide)[colnames(inTextWide)!="Phenotype"]) {
      inTextWide[[cn]] <- as.character(inTextWide[[cn]])
      inTextWide[[cn]][inTextWide[[cn]]=="1"] <- "+"
      inTextWide[[cn]][inTextWide[[cn]]=="-1"] <- "-"
      inTextWide[[cn]][inTextWide[[cn]]=="0"] <- ""
      # remove nonsignificant
      #inTextWide[[cn]][inValueWide[[cn]] > sigValue] <- ""
    }
  } else if (addText == "Significance") {
    doAddText = T
    inTextWide <- as.data.frame(inDirWide)
    for (cn in colnames(inTextWide)[colnames(inTextWide)!="Phenotype"]) {
      inTextWide[[cn]] <- as.character(inTextWide[[cn]])
      inTextWide[[cn]] <- "*"
      # remove nonsignificant
      inTextWide[[cn]][inValueWide[[cn]] > sigValue] <- ""
    }
  }
  # rownames(inTextWide) <- inTextWide$Phenotype
  # inTextWide$Phenotype <- NULL
  # >>> filter dataframes by significance if needed
  #  > heatmap values
  #    > filter by nominal significance
  if (plotValuesSig == "nomSig") {
    if (statToPlot %in% c("Pvalue",	"PadjBH","PadjBonferroni")) {
      inValueWide[inSigNomWide > sigNominal] <- 1.0
    } else {
      inValueWide[inSigNomWide > sigNominal] <- 0.0
    }
  } else if (plotValuesSig == "padjSig") {
    if (statToPlot %in% c("Pvalue",	"PadjBH","PadjBonferroni")) {
      inValueWide[inSigAdjWide > sigValue] <- 1.0
    } else {
      inValueWide[inSigAdjWide > sigValue] <- 0.0
    }
  }
  # > heatmap text
  #    > filter by nominal significance or padj significance
  if (plotTextSig == "nomSig") {
    inTextWide[inSigNomWide > sigNominal] <- ""
  } else if (plotTextSig == "padjSig") {
    inTextWide[inSigAdjWide > sigValue] <- ""
  }
  
  # sort dataframes by number of associations
  dfNRAS <- as.data.frame(apply(inSigAdjWide,MARGIN = 2,FUN = function(x) {sum(x <= sigValue)}))
  dfNRAS$Var <- rownames(dfNRAS)
  colnames(dfNRAS) <- c("NR.Associations","Variable")
  dfNRAS <- dfNRAS[order(dfNRAS$NR.Associations,decreasing = T),]
  toKeep <- dfNRAS$Variable[1:nrFeaturesToPlot]
  
  # >>> transform values
  if (transformValues) {
    if (statToPlot %in% c("Pvalue",	"PadjBH","PadjBonferroni")) {
      inValueWide <- log10(inValueWide)*-1
      for (cn in colnames(inValueWide)) {
        if (!is.na(logLimit)) {
          inValueWide[[cn]][inValueWide[[cn]] > logLimit] <- logLimit
        }
      }
    } else {
      inValueWide <- abs(inValueWide)
      print(nonLogLimit)
      if (!is.na(nonLogLimit)) {
        print(paste0('applying limit: max / min = +/-',nonLogLimit))
        for (cn in colnames(inValueWide)) {
          inValueWide[[cn]][inValueWide[[cn]] > nonLogLimit] <- nonLogLimit
        }
      }
    }
  }
  # >>> now multiply values by direction (for coloring of the plot)
  inValueMulWide <- inValueWide*inDirWide
  
  # >>> make heatmap
  # ==================================
  plotDFValues <- inValueMulWide[colnames(inValueMulWide) %in% toKeep]
  plotDFText <- inTextWide[colnames(inTextWide) %in% toKeep]
  
  # set colors
  plotDFValues <- inValueMulWide[colnames(inValueMulWide) %in% toKeep]
  plotDFText <- inTextWide[colnames(inTextWide) %in% toKeep]
  
  paletteLength <- nrColors
  myColor <- colorRampPalette(c(colLow, "white", colHigh))(paletteLength)
  myBreaks <- c(seq(min(plotDFValues), 0, length.out=ceiling(paletteLength/2) + 1), 
                seq(max(plotDFValues)/paletteLength, max(plotDFValues), length.out=floor(paletteLength/2)))

  # sort (if sortPhenos = T)
  if (sortPhenos) {
    plotDFValues <- plotDFValues[order(rownames(plotDFValues)),]
    plotDFText <- plotDFText[order(rownames(plotDFText)),]
  }
  # keep order (if keepOrder = T)
  if (keepOrder) {
    plotDFValues <- plotDFValues[phenosToPlot,]
    plotDFText <- plotDFText[phenosToPlot,]
  }
  
  if (flipCoords) {
    plotDFValues <- t.data.frame(plotDFValues)
    plotDFText <- t.data.frame(plotDFText)
  }
  if (!flipCoords) {
    tt = clusterPhenos
    clusterPhenos = clusterFeatures
    clusterFeatures = tt
  }
  
  p <- pheatmap(plotDFValues,annotation_row = NULL,annotation_names_row = T,labels_row = rownames(plotDFValues),legend = T,
                show_rownames = T, cluster_rows = clusterFeatures,cluster_cols = clusterPhenos,angle_col = 90,
                fontsize_number = textSize,border_color = "#EEEEEE",na_col = "white",fontsize = legendTextSize,
                treeheight_row = 0, treeheight_col = 0,legend_labels = "sig*log(p-value)",color = myColor,
                fontsize_col = colTextSize,fontsize_row = rowTextSize,display_numbers = plotDFText,breaks = myBreaks,
                cellwidth = cellWidth,cellheight = cellHeight,filename = NA)
  if (retData) {
    list(plotDFValues,plotDFText,p)
  } else {
    p
  }
}
```


```{r}
dag3AssociationsWithCorrections <- function(dataType='taxa',
                                            covariates=c(),
                                            idsToKeep = NULL,
                                            dataPath='./') {
  # define parameters
  dataType = dataType
  #phenoOut = outFile
  pheno2covar = covariates
  # error check
  if (!(dataType %in% c("pathways","taxa","CARD","VFDB") )) {
    stop("ERROR: dataType must be one of [taxa,pathways,CARD,VFDB]")
  }
  ## LOAD DATA
  # ========================================
  print(' > Loading & Preparing Data !')
  workPWD = dataPath
  print ('  >> Taxa')
  # > taxa
  taxa = read.delim(paste0(workPWD,"/Mock_data/taxa.txt"),header=T,row.names=1)
  if (!is.null(idsToKeep)) {
    taxa <- taxa[rownames(taxa) %in% idsToKeep,]
    if (nrow(taxa) == 0) {
      stop("ERROR: No samples kept after subsetting by idsToKeep, quitting!")
    }
  }
  #   > do CLR
  taxa_transformed = do_clr_externalWeighting(taxa,taxa[,grep("[.]s__",colnames(taxa))]) # Performing transformation 
  taxa_transformed = taxa_transformed[,colSums(taxa>0)>nrow(taxa) * 0.05] # Filtering 
  print ('    >> Done!')
  
  # > pathways
  print ('  >> PWYs')
  pathways = read.delim(paste0(workPWD,"/Mock_data/pathways.txt"),header=T,row.names=1)
  if (!is.null(idsToKeep)) {
    pathways <- pathways[rownames(pathways) %in% idsToKeep,]
    if (nrow(pathways) == 0) {
      stop("ERROR: No samples kept after subsetting by idsToKeep, quitting!")
    }
  }
  #   > do CLR
  pathways_transformed = do_clr_externalWeighting(pathways,pathways) # Performing transformation 
  pathways_transformed = pathways_transformed[,colSums(pathways>0)>nrow(pathways)*0.05]# Filtering 
  print ('    >> Done!')
  
  ## > CARD
  print ('  >> CARDs')
  CARD = read.table(paste0(workPWD,"/Mock_data/CARDs.txt"),header=T,sep=' ',stringsAsFactors = F,row.names = 1)
  CARD = CARD[intersect(rownames(CARD),rownames(taxa)),]
  if (!is.null(idsToKeep)) {
    CARD <- CARD[rownames(CARD) %in% idsToKeep,]
    if (nrow(CARD) == 0) {
      stop("ERROR: No samples kept after subsetting by idsToKeep, quitting!")
    }
  }
  #  > do CLR
  CARD_transformed = do_clr_externalWeighting(CARD,CARD)
  #  > filter by prevalence
  CARD_transformed = CARD_transformed[,colSums(CARD>0)>0.05 * nrow(CARD)]
  print ('    >> Done!')

  # VFs
  print ('  >> VFs')
  VFDB = read.table(paste0(workPWD,"/Mock_data/VFs.txt"),header=T,sep=' ',stringsAsFactors = F,row.names = 1)
  VFDB = VFDB[intersect(rownames(taxa),rownames(VFDB)),]
  if (!is.null(idsToKeep)) {
    VFDB <- VFDB[rownames(VFDB) %in% idsToKeep,]
    if (nrow(VFDB) == 0) {
      stop("ERROR: No samples kept after subsetting by idsToKeep, quitting!")
    }
  }
  #  > do CLR
  VFDB_transformed = do_clr_externalWeighting(VFDB,VFDB)
  #  > filter by prevalence
  VFDB_transformed = VFDB_transformed[,colSums(VFDB>0)>0.05 * nrow(VFDB)]
  print ('    >> Done!')
  
  # > load phenotypes. NOTE: only diseases are emulated for phenotype analysis!
  print ('  >> Phenotypes')
  pheno27 = read.table(paste0(workPWD,"/Mock_data/diseases.txt"),header=T,sep="\t") 
  pheno = pheno27[rownames(taxa_transformed),]
  if (!is.null(idsToKeep)) {
    pheno <- pheno[rownames(pheno) %in% idsToKeep,]
    if (nrow(pheno) == 0) {
      stop("ERROR: No samples kept after subsetting by idsToKeep, quitting!")
    }
  }
  print ('    >> Done!')
  
  # ===============================================================
  # prepare covariate data frame
  # ===============================================================
  # > check for missing covariates
  missingCovar <- pheno2covar[!(pheno2covar %in% colnames(pheno))]
  if (length(missingCovar) > 0) {
    print(paste0('WARNING: Covariates < ',paste(missingCovar,collapse=', '),' > missing from phenotype file!'))
  }
  # > technical covariates (these should always be included)
  covar = read.table(paste0(workPWD,"/Mock_data/covariates.txt"),sep='\t',header=T,row.names=1) 
  # remove covariates from phenotypes
  #pheno$META.BATCH <- NULL
  #pheno$META.DNA.conc.ng.ul <- NULL
  #pheno$META.POOP.COLLECTION_SEASON <- NULL
  #pheno$ANTHRO.AGE <- NULL
  #pheno$ANTHRO.Sex <- NULL
  
  # clean covariate matrix & add extra covariates
  covar = covar[rownames(taxa_transformed),]
  covar = data.frame(covar,pheno[,which(colnames(pheno) %in% pheno2covar),drop = F])
  
  # drop extra covariates
  pheno <- pheno[,!(colnames(pheno) %in% pheno2covar)]
  pheno <- pheno[,!(colnames(pheno) %in% colnames(covar) )]
  
  # ===========================================
  # RUN ANALYSIS
  # ===========================================
  print (paste0(" > Building associations models for ",dataType,""))
  # ===========================================
  
  # ERROR TESTS
  # ==========================================
  if (dataType=="pathways") {
    ftrs_transformed = pathways_transformed
  } else if (dataType=="CARD"){
    ftrs_transformed = CARD_transformed
  } else if (dataType == "VFDB") {
    ftrs_transformed = VFDB_transformed
  } else if (dataType == "taxa") {
    ftrs_transformed = taxa_transformed
  } else {
    quit ("ERROR:wrong data type requested!")
  }
  
  # ====================================================
  # Run multivariate models, multi-thread implementation
  # ======================================================
  # prep parallelization
  registerDoSEQ() # debug mode = single threaded
  #registerDoParallel(makeCluster(8))
  # debug: timer
  # t1 <- Sys.time()
  # loop over all phenotypes
  result_ftrs = foreach(i = 1:ncol(pheno),.combine = rbind) %:%
    
    #result_ftrs = foreach(i = 1:50,.combine = rbind) %:%     # debug/test
    
    # loop over all features of requested type (ftrs, VFs, PWYs or CARDs)
    # ==========================================================================
    foreach(j = 1:ncol(ftrs_transformed),.combine = rbind) %do% { # single-threaded implementation for debug
    
    #foreach(j = 1:ncol(ftrs_transformed),.combine = rbind) %dopar% {  # parallel implementation
      #debug output/mode
      #foreach(j = 1:50,.combine = rbind) %dopar% {  #debug/test
      #print(i)
      #print(j)
      predictors = data.frame(covar[!is.na(pheno[,i]),],
                              model.matrix(
                                as.formula(paste0("~ ",colnames(pheno)[i])),data = pheno)[,-1,drop = F])
      
      cleaned_data = predictors[complete.cases(predictors),]
      rn <- rownames(cleaned_data)
      rn <- rn[rn %in% rownames(ftrs_transformed)]
      ftrs.cleaned = ftrs_transformed[rn,]
      cleaned_data = cleaned_data[rn,]
      if (nrow(cleaned_data) > 3) {
        # debug: print model
        #print(paste("ftrs.cleaned[,j] ~ ",paste(collapse=" + ",colnames(cleaned_data))))
        
        # make model
        s1 = lm(
          as.formula(paste("ftrs.cleaned[,j] ~ ",paste(collapse=" + ",colnames(cleaned_data)))),
          data = cleaned_data
        )
        # debug: print model
        #print(paste("ftrs.cleaned[,j] ~ ",paste(collapse=" + ",colnames(cleaned_data)[1:ncol(covar)])))
        
        # make model with extra covariates
        s0 = lm(
          as.formula(paste("ftrs.cleaned[,j] ~ ",paste(collapse=" + ",colnames(cleaned_data)[1:ncol(covar)]))),
          data = cleaned_data
        )
        
        # compare models
        an1 = anova(s1,s0)
        output = data.frame(
          phenotype = colnames(pheno)[i],
          taxon = colnames(ftrs.cleaned)[j],
          Nsamples = nrow(cleaned_data),
          levels = if(class(pheno[,i]) == "factor") paste(collapse=":",levels(pheno[,i])) else "Not Applicable",
          levels_SampleSize = 
            if(class(pheno[,i]) == "factor" | length(table(pheno[,i]))==2) paste(collapse= ":",table(pheno[,i])) else "Not Applicable",
          effect.size = if(class(pheno[,i]) == "factor") {paste(collapse = ":",c(0,round(digits = 5, s1$coef[grep(colnames(pheno)[i],names(s1$coef))])))}
          else round(digits = 5, s1$coef[grep(colnames(pheno)[i],names(s1$coef))]) ,
          
          R2 = summary(s1)$r.squared- summary(s0)$r.squared,
          F.stat = an1[2,5],
          Pvalue = an1[2,6]
        )
        #add covariates
        output
      }
    }
  # debug
  #t2 <-  Sys.time()
  print("ftrs_done")
  # debug
  #print(t2-t1)
  rownames(result_ftrs) <- NULL
  result_ftrs$FDR <- p.adjust(result_ftrs$Pvalue,method = "BH")
  #write.table(,file = phenoOut,row.names=F,quote = F,sep="\t")
  
  #close parallelization
  registerDoSEQ()
  # return results
  result_ftrs
}
```


Running associations
```{r}





covs <- c()#"BMI","META.POOP.BristolMean","META.DNA.postclean.reads")

# loop over data layer, run associations for each:
for (dataType in c("pathways","taxa","CARD","VFDB")) {
  phenoOut <- paste0("associations_",dataType,"_corrected_BMI_Bristol.txt")
  res <- dag3AssociationsWithCorrections(dataType = dataType,
                                         dataPath = '.',
                                         covariates = covs)
  if (!dir.exists('association_analysis/MockData.output')) {
    dir.create('association_analysis/MockData.output')
  }
  write.table(res,paste0('association_analysis/MockData.output/',phenoOut),sep=',',row.names = F)
}
```



PLotting
```{r}
# function for linking phenotypes to phenotype groups
remapPhenos <- function(inPh) {
  out <- c()
  cc = 0
  for (inP in inPh) {
    cc = cc + 1
    if (cc %% 5000 == 0) {
      print(cc)
    }
    mm <- grep(paste0('^',inP,'$'),inRename$Phenotype)
    if (length(mm) == 1) {
      inPh2 <- inRename$Group.renamed[mm]
    } else {
      inPh2 <- inP 
    }
    out <- c(out,inPh2)
  }
  out
}

statToPlot <- "z.score"

# file with phenotype groups
inRename <- read.table('association_analysis/data/phenotype_groups.csv',sep=',',header=T,stringsAsFactors = F)

# =========================================================================
# =================== HEALTHY MICROBIOME PLOTS (Fig 4/a) ======================
# =========================================================================
print(' >> loading data ...')
inData <- read.table('association_analysis/data/DAG3_v27d_supplementary_tables_S3B.txt',sep='\t',header=T,stringsAsFactors = F)
inDF <- inData
inDF$effect.size.asInteger <- inDF$effect.size
inDF$PadjBH <- inDF$FDR
inDF$PadjBonferroni <- inDF$FDR
print(' >> grouping and cleaning phenotypenames (takes a bit) ...')
inDF$phenotype <- remapPhenos(inDF$phenotype)



phenosToPlot <- c(
  # ======================
  # diet
  # ======================
  "EXP.DIET.Amounts.GlycLoadTotal",
  "EXP.DIET.Amounts.KcalTotal",
  "EXP.DIET.ECorrected.AlchAll",
  "EXP.DIET.ECorrected.CarbsAll",
  "EXP.DIET.ECorrected.FatAll",
  "EXP.DIET.ECorrected.ProtAnimal",
  "EXP.DIET.ECorrected.ProtPlant",
  "EXP.DIET.Probiotics",
  "EXP.DIET.Scores.LLDietScore",
  # ==========================
  # baby phenotypes
  # ==========================
  "EXP.EARLYLIFE.Preg.Mother.Smoking",
  "EXP.EARLYLIFE.PretermBorn",
  "EXP.EARLYLIFE.Birth.Mode",
  "EXP.BIRTH.Breastfed.6.M.Plus",
  # ==========================
  # childhood phenotypes
  # ==========================
  "EXP.EARLYLIFE.LIVINGPLACE.child.1.4",
  "EXP.EARLYLIFE.Parent.smoker.childhood",
  "EXP.EARLYLIFE.PETS.child.0.15.Any",
  # ==========================
  # current exposome
  # ==========================
  "EXP.GREENSPACE.NDVI.100m",
  "EXP.PETS.now.Any",
  "EXP.POLLUTION.NO2",
  "EXP.POLLUTION.PM2.5",
  "SOCIOECONOMIC.BUURT.Urbanicity",
  "EXP.SMOKING.Passive",
  "EXP.SMOKING.Smoker.Now",
  "EXP.SMOKING.Smoker.OneYear.Ever",
  "EXP.SMOKING.Smoker.stopped",
  # ==============================
  # socioeconomics
  # ==============================
  "SOCIOEC.INCOME.Income.Month",
  "SOCIOEC.STATUS.Retired",
  "SOCIOEC.WORK.Housewife.husband",
  "SOCIOEC.WORK.Paidwork.any",
  "SOCIOECONOMIC.BUURT.Highincome.Pop.Prop",
  # ========= health for comparison =======
  "MED.HEALTH.RAND.Health.General.asInteger"
)
nrPhenos <- length(phenosToPlot)
phenosToPlot <- remapPhenos(phenosToPlot)
#phenosToPlot <- trimPhenos(phenosToPlot)

# ==== Species Plot, sorted ===
nrFeatures = 40
#phenosToPlot <- phenosToPlot[order(phenosToPlot)]
print(paste0(' >> PLOTTING Exposome vs Species'))
#phenosToPlot <- as.character(phenosToPlot)
phm <- plotAssociationsDag3HeatmapV2(inData = inDF, # data
                                     phenosToPlot = phenosToPlot, # what is plotted
                                     statToPlot = statToPlot,
                                     featuresToPlot = "S", # plot genera (All plots everthing, Taxa plots all taxa, S/O/F/... plots appropriate levels)
                                     nrFeaturesToPlot = nrFeatures, # how many top shared features to plot
                                     nrColors = 51, # increase number of colors for gradient
                                     clusterPhenos = F,
                                     clusterFeatures = T,
                                     sortPhenos = F,
                                     retData = T,
                                     keepOrder = T,
                                     flipCoords = F)
```

